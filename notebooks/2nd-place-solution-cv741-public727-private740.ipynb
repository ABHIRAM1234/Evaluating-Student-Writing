{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b9bd55",
   "metadata": {
    "papermill": {
     "duration": 0.014055,
     "end_time": "2022-03-17T03:28:44.470058",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.456003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2nd Place Solution - CV 741, Public 727, Private 740\n",
    "We (Chun Ming Lee @leecming , Udbhav Bamba @ubamba98, and Chris Deotte @cdeotte ) are excited to present our 2nd place solution to Kaggle's \"Feedback Prize - Evaluating Student Writing\" Competition. Thank you Georgia State University, The Learning Agency Lab, and Kaggle for an awesome competition.\n",
    "\n",
    "Our full solution write up is [here][1]. The main ingredients to our solution are \n",
    "* powerful post process per model\n",
    "* huge variety of NLP models trained on NER task\n",
    "* ensemble with weighted box fusion (from ZFTurbo's GitHub [here][3]). \n",
    "\n",
    "[1]: https://www.kaggle.com/c/feedback-prize-2021/discussion/313389\n",
    "[3]: https://github.com/ZFTurbo/Weighted-Boxes-Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b0603",
   "metadata": {
    "papermill": {
     "duration": 0.01233,
     "end_time": "2022-03-17T03:28:44.496178",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.483848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference Script with Post Process\n",
    "The following Python script accepts a filename of a saved model, infers the test texts, applies post process, and writes a `submission.csv` file with an extra column of confidence scores per span (i.e. the probability that this span is correct). **Click \"show hidden cell\" to see the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd457395",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-03-17T03:28:44.527036Z",
     "iopub.status.busy": "2022-03-17T03:28:44.525289Z",
     "iopub.status.idle": "2022-03-17T03:28:44.547452Z",
     "shell.execute_reply": "2022-03-17T03:28:44.548073Z",
     "shell.execute_reply.started": "2022-03-13T07:39:00.274808Z"
    },
    "papermill": {
     "duration": 0.039585,
     "end_time": "2022-03-17T03:28:44.548335",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.508750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing generate_preds.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile generate_preds.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('--model_paths', nargs='+', required=True)\n",
    "ap.add_argument(\"--save_name\", type=str, required=True)\n",
    "ap.add_argument(\"--max_len\", type=int, required=True)\n",
    "args = ap.parse_args()\n",
    "\n",
    "if args.save_name == \"yoso\":\n",
    "    os.system(\"cp -r ../input/hf-transformers/transformers-4.16.0 .\")\n",
    "    os.system(\"pip install -U --no-build-isolation --no-deps /kaggle/working/transformers-4.16.0\")\n",
    "    \n",
    "if (\"v3\" in args.save_name)|(\"v2\" in args.save_name):\n",
    "    # https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizer\n",
    "    # The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "    # This must be done before importing transformers\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "\n",
    "    transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "    input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "\n",
    "    convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "    conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "    if conversion_path.exists():\n",
    "        conversion_path.unlink()\n",
    "\n",
    "    shutil.copy(convert_file, transformers_path)\n",
    "    deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "    for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "        filepath = deberta_v2_path/filename\n",
    "        if filepath.exists():\n",
    "            filepath.unlink()\n",
    "\n",
    "        shutil.copy(input_dir/filename, filepath)\n",
    "\n",
    "if args.save_name == \"longformerwithlstm\":\n",
    "    os.system(\"cp -r ../input/longformerwithbilstmhead/model.py .\")\n",
    "    from model import LongformerForTokenClassificationwithbiLSTM\n",
    "    \n",
    "if args.save_name == \"debertawithlstm\":\n",
    "    os.system(\"cp -r ../input/deberta-lstm/model.py .\")\n",
    "    from model import DebertaForTokenClassificationwithbiLSTM\n",
    "        \n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import multiprocessing as mp\n",
    "from scipy.special import softmax\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (AutoModelForTokenClassification, \n",
    "                          AutoTokenizer, \n",
    "                          TrainingArguments, \n",
    "                          Trainer)\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "NUM_CORES = 16\n",
    "BATCH_SIZE = 4\n",
    "MAX_SEQ_LENGTH = args.max_len\n",
    "PRETRAINED_MODEL_PATHS = args.model_paths\n",
    "if \"debertal_chris\" in args.save_name:\n",
    "    print('==> using -1 in offset mapping...')\n",
    "if (\"v3\" in args.save_name)|(\"v2\" in args.save_name):\n",
    "    print('==> using -1 in offset mapping...')\n",
    "    \n",
    "AGG_FUNC = np.mean\n",
    "print('==> using span token mean...')\n",
    "\n",
    "TEST_DIR = '../input/feedback-prize-2021/test/'\n",
    "\n",
    "MIN_TOKENS = {\n",
    "    \"Lead\": 32,\n",
    "    \"Position\": 5,\n",
    "    \"Evidence\": 35,\n",
    "    \"Claim\": 7,\n",
    "    \"Concluding Statement\": 6,\n",
    "    \"Counterclaim\": 6,\n",
    "    \"Rebuttal\": 6\n",
    "}\n",
    "\n",
    "if \"chris\" not in args.save_name:\n",
    "    ner_labels = {'O': 0,\n",
    "                  'B-Lead': 1,\n",
    "                  'I-Lead': 2,\n",
    "                  'B-Position': 3,\n",
    "                  'I-Position': 4,\n",
    "                  'B-Evidence': 5,\n",
    "                  'I-Evidence': 6,\n",
    "                  'B-Claim': 7,\n",
    "                  'I-Claim': 8,\n",
    "                  'B-Concluding Statement': 9,\n",
    "                  'I-Concluding Statement': 10,\n",
    "                  'B-Counterclaim': 11,\n",
    "                  'I-Counterclaim': 12,\n",
    "                  'B-Rebuttal': 13,\n",
    "                  'I-Rebuttal': 14}\n",
    "else:\n",
    "    print(\"==> Using Chris BIO\")\n",
    "    ner_labels = {'O': 14,\n",
    "                  'B-Lead': 0,\n",
    "                  'I-Lead': 1,\n",
    "                  'B-Position': 2,\n",
    "                  'I-Position': 3,\n",
    "                  'B-Evidence': 4,\n",
    "                  'I-Evidence': 5,\n",
    "                  'B-Claim': 6,\n",
    "                  'I-Claim': 7,\n",
    "                  'B-Concluding Statement': 8,\n",
    "                  'I-Concluding Statement': 9,\n",
    "                  'B-Counterclaim': 10,\n",
    "                  'I-Counterclaim': 11,\n",
    "                  'B-Rebuttal': 12,\n",
    "                  'I-Rebuttal': 13}\n",
    "\n",
    "\n",
    "inverted_ner_labels = dict((v,k) for k,v in ner_labels.items())\n",
    "inverted_ner_labels[-100] = 'Special Token'\n",
    "\n",
    "test_files = os.listdir(TEST_DIR)\n",
    "\n",
    "# accepts file path, returns tuple of (file_ID, txt split, NER labels)\n",
    "def generate_text_for_file(input_filename):\n",
    "    curr_id = input_filename.split('.')[0]\n",
    "    with open(os.path.join(TEST_DIR, input_filename)) as f:\n",
    "        curr_txt = f.read()\n",
    "\n",
    "    return curr_id, curr_txt\n",
    "\n",
    "with mp.Pool(NUM_CORES) as p:\n",
    "    ner_test_rows = p.map(generate_text_for_file, test_files)\n",
    "    \n",
    "if (\"v3\" in args.save_name)|(\"v2\" in args.save_name):\n",
    "    from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(PRETRAINED_MODEL_PATHS[0])\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_PATHS[0])\n",
    "# Check is rust-based fast tokenizer\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
    "\n",
    "ner_test_rows = sorted(ner_test_rows, key=lambda x: len(tokenizer(x[1], max_length=MAX_SEQ_LENGTH, truncation=True)['input_ids']))\n",
    "\n",
    "# tokenize and store word ids\n",
    "def tokenize_with_word_ids(ner_raw_data):\n",
    "    # ner_raw_data is shaped (num_examples, 3) where cols are (ID, words, word-level labels)\n",
    "    tokenized_inputs = tokenizer([x[1] for x in ner_raw_data], \n",
    "                                 max_length=MAX_SEQ_LENGTH,\n",
    "                                 return_offsets_mapping=True,\n",
    "                                 truncation=True)\n",
    "    \n",
    "    tokenized_inputs['id'] = [x[0] for x in ner_raw_data]\n",
    "    tokenized_inputs['offset_mapping'] = [tokenized_inputs['offset_mapping'][i] for i in range(len(ner_raw_data))]\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_all = tokenize_with_word_ids(ner_test_rows)\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, input_dict):\n",
    "        self.input_dict = input_dict\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return {k:self.input_dict[k][index] for k in self.input_dict.keys() if k not in {'id', 'offset_mapping'}}\n",
    "    \n",
    "    def get_filename(self, index):\n",
    "        return self.input_dict['id'][index]\n",
    "    \n",
    "    def get_offset(self, index):\n",
    "        return self.input_dict['offset_mapping'][index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_dict['input_ids'])\n",
    "\n",
    "test_dataset = NERDataset(tokenized_all)\n",
    "\n",
    "soft_predictions = None\n",
    "hfargs = TrainingArguments(output_dir='None',\n",
    "                         log_level='warning',\n",
    "                         per_device_eval_batch_size=BATCH_SIZE)\n",
    "\n",
    "for idx, curr_path in enumerate(PRETRAINED_MODEL_PATHS):\n",
    "\n",
    "    if args.save_name == \"longformerwithlstm\":\n",
    "        model = LongformerForTokenClassificationwithbiLSTM.from_pretrained(curr_path)\n",
    "    elif args.save_name == \"debertawithlstm\":\n",
    "        model = DebertaForTokenClassificationwithbiLSTM.from_pretrained(curr_path)\n",
    "    else:\n",
    "        model = AutoModelForTokenClassification.from_pretrained(curr_path, trust_remote_code=True)\n",
    "    trainer = Trainer(model,\n",
    "                      hfargs,\n",
    "                      tokenizer=tokenizer)\n",
    "    \n",
    "    curr_preds, _, _ = trainer.predict(test_dataset)\n",
    "    curr_preds = curr_preds.astype(np.float16)\n",
    "    curr_preds = softmax(curr_preds, -1)\n",
    "\n",
    "    if soft_predictions is not None:\n",
    "        soft_predictions = soft_predictions + curr_preds\n",
    "    else:\n",
    "        soft_predictions = curr_preds\n",
    "        \n",
    "    del model, trainer, curr_preds\n",
    "    gc.collect()\n",
    "\n",
    "soft_predictions = soft_predictions / len(PRETRAINED_MODEL_PATHS)\n",
    "\n",
    "soft_claim_predictions = soft_predictions[:, :, 8]\n",
    "\n",
    "predictions = np.argmax(soft_predictions, axis=2)\n",
    "soft_predictions = np.max(soft_predictions, axis=2)\n",
    "\n",
    "def generate_token_to_word_mapping(txt, offset):\n",
    "    # GET WORD POSITIONS IN CHARS\n",
    "    w = []\n",
    "    blank = True\n",
    "    for i in range(len(txt)):\n",
    "        if not txt[i].isspace() and blank==True:\n",
    "            w.append(i)\n",
    "            blank=False\n",
    "        elif txt[i].isspace():\n",
    "            blank=True\n",
    "    w.append(1e6)\n",
    "\n",
    "    # MAPPING FROM TOKENS TO WORDS\n",
    "    word_map = -1 * np.ones(len(offset),dtype='int32')\n",
    "    w_i = 0\n",
    "    for i in range(len(offset)):\n",
    "        if offset[i][1]==0: continue\n",
    "        while offset[i][0]>=(w[w_i+1]-(\"debertal_chris\" in args.save_name)-(\"v3\" in args.save_name)\\\n",
    "                             -(\"v2\" in args.save_name) ): w_i += 1\n",
    "        word_map[i] = int(w_i)\n",
    "\n",
    "    return word_map\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "# Clumsy gathering of predictions at word lvl - only populate with 1st subword pred\n",
    "for curr_sample_id in range(len(test_dataset)):\n",
    "    curr_preds = []\n",
    "    sample_preds = predictions[curr_sample_id]\n",
    "    sample_offset = test_dataset.get_offset(curr_sample_id)\n",
    "    sample_txt = ner_test_rows[curr_sample_id][1]\n",
    "    sample_word_map = generate_token_to_word_mapping(sample_txt, sample_offset)\n",
    "\n",
    "    word_preds = [''] * (max(sample_word_map) + 1)\n",
    "    word_probs = dict(zip(range((max(sample_word_map) + 1)),[0]*(max(sample_word_map) + 1)))\n",
    "    claim_probs = dict(zip(range((max(sample_word_map) + 1)),[0]*(max(sample_word_map) + 1)))\n",
    "\n",
    "    for i, curr_word_id in enumerate(sample_word_map):\n",
    "        if curr_word_id != -1:\n",
    "            if word_preds[curr_word_id] == '': # only use 1st subword\n",
    "                word_preds[curr_word_id] = inverted_ner_labels[sample_preds[i]]\n",
    "                word_probs[curr_word_id] = soft_predictions[curr_sample_id, i]\n",
    "                claim_probs[curr_word_id] = soft_claim_predictions[curr_sample_id, i]\n",
    "            elif 'B-' in inverted_ner_labels[sample_preds[i]]:\n",
    "                word_preds[curr_word_id] = inverted_ner_labels[sample_preds[i]]\n",
    "                word_probs[curr_word_id] = soft_predictions[curr_sample_id, i]\n",
    "                claim_probs[curr_word_id] = soft_claim_predictions[curr_sample_id, i]\n",
    "\n",
    "    # Dict to hold Lead, Position, Concluding Statement\n",
    "    let_one_dict = dict() # K = Type, V = (Prob of start token, start, end)\n",
    "\n",
    "    # If we see tokens I-X, I-Y, I-X -> change I-Y to I-X\n",
    "    for j in range(1, len(word_preds) - 1):\n",
    "        pred_trio = [word_preds[k] for k in [j - 1, j, j + 1]]\n",
    "        splitted_trio = [x.split('-')[0] for x in pred_trio]\n",
    "        if all([x == 'I' for x in splitted_trio]) and pred_trio[0] == pred_trio[2] and pred_trio[0] != pred_trio[1]:\n",
    "            word_preds[j] = word_preds[j-1]\n",
    "\n",
    "    # B-X, ? (not B), I-X -> change ? to I-X\n",
    "    for j in range(1, len(word_preds) - 1):\n",
    "        if 'B-' in word_preds[j-1] and word_preds[j+1] == f\"I-{word_preds[j-1].split('-')[-1]}\" and word_preds[j] != word_preds[j+1] and 'B-' not in word_preds[j]:\n",
    "            word_preds[j] = word_preds[j+1]\n",
    "\n",
    "     # If we see tokens I-X, O, I-X, change center token to the same for stated discourse types\n",
    "    for j in range(1, len(word_preds) - 1):\n",
    "        if word_preds[j - 1] in ['I-Lead', 'I-Position', 'I-Concluding Statement'] and word_preds[j-1] == word_preds[j+1] and word_preds[j] == 'O':\n",
    "            word_preds[j] = word_preds[j-1]\n",
    "\n",
    "    j = 0 # start of candidate discourse\n",
    "    while j < len(word_preds): \n",
    "        cls = word_preds[j] \n",
    "        cls_splitted = cls.split('-')[-1]\n",
    "        end = j + 1 # try to extend discourse as far as possible\n",
    "\n",
    "        if word_probs[j] > 0.54: \n",
    "            # Must match suffix i.e., I- to I- only; no B- to I-\n",
    "            while end < len(word_preds) and (word_preds[end].split('-')[-1] == cls_splitted if cls_splitted in ['Lead', 'Position', 'Concluding Statement'] else word_preds[end] == f'I-{cls_splitted}'):\n",
    "                end += 1\n",
    "            # if we're here, end is not the same pred as start\n",
    "            if cls != 'O' and (end - j > MIN_TOKENS[cls_splitted] or max(word_probs[l] for l in range(j, end)) > 0.73): # needs to be longer than class-specified min\n",
    "                if cls_splitted in ['Lead', 'Position', 'Concluding Statement']:\n",
    "                    lpc_max_prob = max(word_probs[c] for c in range(j, end))\n",
    "                    if cls_splitted in let_one_dict: # Already existing, check contiguous or higher prob\n",
    "                        prev_prob, prev_start, prev_end = let_one_dict[cls_splitted]\n",
    "                        if cls_splitted in ['Lead', 'Concluding Statement'] and j - prev_end < 49: # If close enough, combine\n",
    "                            let_one_dict[cls_splitted] = (max(prev_prob, lpc_max_prob), prev_start, end)\n",
    "                            \n",
    "                            # Delete other preds that lie inside the joined LC discourse\n",
    "                            for l in range(len(curr_preds) - 1, 0, -1):\n",
    "                                check_span = curr_preds[l][2]\n",
    "                                check_start, check_end = int(check_span[0]), int(check_span[-1])\n",
    "                                if check_start > prev_start and check_end < end:\n",
    "                                    del curr_preds[l]\n",
    "                            \n",
    "                        elif lpc_max_prob > prev_prob: # Overwrite if current candidate is more likely\n",
    "                            let_one_dict[cls_splitted] = (lpc_max_prob, j, end)\n",
    "                    else: # Add to it\n",
    "                        let_one_dict[cls_splitted] = (lpc_max_prob, j, end)\n",
    "                else:\n",
    "                    # Lookback and add preceding I- tokens\n",
    "                    while j - 1 > 0 and word_preds[j-1] == cls:\n",
    "                        j = j - 1\n",
    "                    # Try to add the matching B- tag if immediately precedes the current I- sequence\n",
    "                    if j - 1 > 0 and word_preds[j-1] == f'B-{cls_splitted}':\n",
    "                        j = j - 1\n",
    "\n",
    "\n",
    "                    #############################################################\n",
    "                    # Run a bunch of adjustments to discourse predictions based on CV \n",
    "                    adj_start, adj_end = j, end + 1\n",
    "\n",
    "                    # Run some heuristics against previous discourse\n",
    "                    if len(curr_preds) > 0:\n",
    "                        prev_span = list(map(int, curr_preds[-1][2].split()))\n",
    "                        prev_start, prev_end = prev_span[0], prev_span[-1]\n",
    "\n",
    "                        # Join adjacent rebuttals\n",
    "                        if cls_splitted in 'Rebuttal':                        \n",
    "                            if curr_preds[-1][1] == cls_splitted and adj_start - prev_end < 32:\n",
    "                                del curr_preds[-1]\n",
    "                                combined_list = prev_span + list(range(adj_start, adj_end))                                \n",
    "                                curr_preds.append((test_dataset.get_filename(curr_sample_id), \n",
    "                                                   cls_splitted, \n",
    "                                                   ' '.join(map(str, combined_list)),\n",
    "                                                   AGG_FUNC([word_probs[i] for i in combined_list if i in word_probs.keys()])))\n",
    "                                j = end\n",
    "                                continue\n",
    "                                \n",
    "                        elif cls_splitted in 'Counterclaim':                        \n",
    "                            if curr_preds[-1][1] == cls_splitted and adj_start - prev_end < 24:\n",
    "                                del curr_preds[-1]\n",
    "                                combined_list = prev_span + list(range(adj_start, adj_end))                                \n",
    "                                curr_preds.append((test_dataset.get_filename(curr_sample_id), \n",
    "                                                   cls_splitted, \n",
    "                                                   ' '.join(map(str, combined_list)),\n",
    "                                                  AGG_FUNC([word_probs[i] for i in combined_list if i in word_probs.keys()])))\n",
    "                                j = end\n",
    "                                continue\n",
    "\n",
    "                        elif cls_splitted in 'Evidence':                        \n",
    "                            if curr_preds[-1][1] == cls_splitted and 8 < adj_start - prev_end < 25:\n",
    "                                if max(claim_probs[l] for l in range(prev_end+1, adj_start)) > 0.35:\n",
    "                                    claim_tokens = [str(l) for l in range(prev_end+1, adj_start) if claim_probs[l] > 0.15]\n",
    "                                    if len(claim_tokens) > 2:\n",
    "                                        curr_preds.append((test_dataset.get_filename(curr_sample_id), \n",
    "                                                           'Claim', \n",
    "                                                           ' '.join(claim_tokens),\n",
    "                                                           AGG_FUNC([word_probs[int(i)] for i in claim_tokens if int(i) in word_probs.keys()])))\n",
    "                        # If gap with discourse of same type, extend to it \n",
    "                        elif curr_preds[-1][1] == cls_splitted and adj_start - prev_end > 2:\n",
    "                            adj_start -= 1\n",
    "\n",
    "                    # Adjust discourse lengths if too long or short\n",
    "                    if cls_splitted == 'Evidence':\n",
    "                        if adj_end - adj_start < 45:\n",
    "                            adj_start -= 9\n",
    "                        else:\n",
    "                            adj_end -= 1\n",
    "                    elif cls_splitted == 'Claim':\n",
    "                        if adj_end - adj_start > 24:\n",
    "                            adj_end -= 1\n",
    "                    elif cls_splitted == 'Counterclaim':\n",
    "                        if adj_end - adj_start > 24:\n",
    "                            adj_end -= 1\n",
    "                        else:\n",
    "                            adj_start -= 1\n",
    "                            adj_end += 1\n",
    "                    elif cls_splitted == 'Rebuttal':\n",
    "                        if adj_end - adj_start > 32:\n",
    "                            adj_end -= 1\n",
    "                        else:\n",
    "                            adj_start -= 1\n",
    "                            adj_end += 1\n",
    "                    adj_start = max(0, adj_start)\n",
    "                    adj_end = min(len(word_preds) - 1, adj_end)\n",
    "                    curr_preds.append((test_dataset.get_filename(curr_sample_id), \n",
    "                                       cls_splitted, \n",
    "                                       ' '.join(map(str, list(range(adj_start, adj_end)))),\n",
    "                                       AGG_FUNC([word_probs[i] for i in range(adj_start, adj_end) if i in word_probs.keys()])))\n",
    "\n",
    "        j = end \n",
    "\n",
    "    # Add the Lead, Position, Concluding Statement\n",
    "    for k, v in let_one_dict.items():\n",
    "        pred_start = v[1]\n",
    "        pred_end = v[2]\n",
    "\n",
    "        # Lookback and add preceding I- tokens\n",
    "        while pred_start - 1 > 0 and word_preds[pred_start-1] == f'I-{k}':\n",
    "            pred_start = pred_start - 1\n",
    "        # Try to add the matching B- tag if immediately precedes the current I- sequence\n",
    "        if pred_start - 1 > 0 and word_preds[pred_start - 1] == f'B-{k}':\n",
    "            pred_start = pred_start - 1\n",
    "\n",
    "        # Extend short Leads and Concluding Statements\n",
    "        if k == 'Lead':\n",
    "            if pred_end - pred_start < 33:\n",
    "                pred_end = min(len(word_preds), pred_end + 5)\n",
    "            else:\n",
    "                pred_end -= 5\n",
    "        elif k == 'Concluding Statement':\n",
    "            if pred_end - pred_start < 23:\n",
    "                pred_start = max(0, pred_start - 1)\n",
    "                pred_end = min(len(word_preds), pred_end + 10)\n",
    "        elif k == 'Position':\n",
    "            if pred_end - pred_start < 18:\n",
    "                pred_end = min(len(word_preds), pred_end + 3)\n",
    "\n",
    "        pred_start = max(0, pred_start)\n",
    "        if pred_end - pred_start > 6:\n",
    "            curr_preds.append((test_dataset.get_filename(curr_sample_id), \n",
    "                               k, \n",
    "                               ' '.join(map(str, list(range(pred_start, pred_end)))),\n",
    "                               AGG_FUNC([word_probs[i] for i in range(pred_start, pred_end) if i in word_probs.keys()])))\n",
    "\n",
    "    all_preds.extend(curr_preds)\n",
    "\n",
    "output_df = pd.DataFrame(all_preds)\n",
    "output_df.columns = ['id', 'class', 'predictionstring', 'scores']\n",
    "output_df.to_csv(f'{args.save_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296dbe46",
   "metadata": {
    "papermill": {
     "duration": 0.013048,
     "end_time": "2022-03-17T03:28:44.575538",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.562490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weighted Box Fusion\n",
    "The following code comes from ZFTurbo's GitHub [here][1]. First, the text `predictionstring` are converted to 1 dimensional boxes. Next they are ensembled with ZFTurbo's WBF code. **Click \"show hidden cell\" to see the code.**\n",
    "\n",
    "[1]: https://github.com/ZFTurbo/Weighted-Boxes-Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669e2f91",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-03-17T03:28:44.611901Z",
     "iopub.status.busy": "2022-03-17T03:28:44.610413Z",
     "iopub.status.idle": "2022-03-17T03:28:44.760402Z",
     "shell.execute_reply": "2022-03-17T03:28:44.759935Z",
     "shell.execute_reply.started": "2022-03-13T07:39:00.315448Z"
    },
    "papermill": {
     "duration": 0.172084,
     "end_time": "2022-03-17T03:28:44.760556",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.588472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code taken and modified for 1D sequences from:\n",
    "https://github.com/ZFTurbo/Weighted-Boxes-Fusion/blob/master/ensemble_boxes/ensemble_boxes_wbf.py\n",
    "'''\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "def prefilter_boxes(boxes, scores, labels, weights, thr):\n",
    "    # Create dict with boxes stored by its label\n",
    "    new_boxes = dict()\n",
    "\n",
    "    for t in range(len(boxes)):\n",
    "\n",
    "        if len(boxes[t]) != len(scores[t]):\n",
    "            print('Error. Length of boxes arrays not equal to length of scores array: {} != {}'.format(len(boxes[t]), len(scores[t])))\n",
    "            exit()\n",
    "\n",
    "        for j in range(len(boxes[t])):\n",
    "            score = scores[t][j]\n",
    "            if score < thr:\n",
    "                continue\n",
    "            label = labels[t][j]\n",
    "            box_part = boxes[t][j]\n",
    "\n",
    "            x = float(box_part[0])\n",
    "            y = float(box_part[1])\n",
    "\n",
    "            # Box data checks\n",
    "            if y < x:\n",
    "                warnings.warn('Y < X value in box. Swap them.')\n",
    "                x, y = y, x\n",
    "\n",
    "            # [label, score, weight, model index, x, y]\n",
    "            b = [label, float(score) * weights[t], weights[t], t, x, y]\n",
    "            if label not in new_boxes:\n",
    "                new_boxes[label] = []\n",
    "            new_boxes[label].append(b)\n",
    "\n",
    "    # Sort each list in dict by score and transform it to numpy array\n",
    "    for k in new_boxes:\n",
    "        current_boxes = np.array(new_boxes[k])\n",
    "        new_boxes[k] = current_boxes[current_boxes[:, 1].argsort()[::-1]]\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "def get_weighted_box(boxes, conf_type='avg'):\n",
    "    \"\"\"\n",
    "    Create weighted box for set of boxes\n",
    "    :param boxes: set of boxes to fuse\n",
    "    :param conf_type: type of confidence one of 'avg' or 'max'\n",
    "    :return: weighted box (label, score, weight, model index, x, y)\n",
    "    \"\"\"\n",
    "\n",
    "    box = np.zeros(6, dtype=np.float32)\n",
    "    conf = 0\n",
    "    conf_list = []\n",
    "    w = 0\n",
    "    for b in boxes:\n",
    "        box[4:] += (b[1] * b[4:])\n",
    "        conf += b[1]\n",
    "        conf_list.append(b[1])\n",
    "        w += b[2]\n",
    "    box[0] = boxes[0][0]\n",
    "    if conf_type == 'avg':\n",
    "        box[1] = conf / len(boxes)\n",
    "    elif conf_type == 'max':\n",
    "        box[1] = np.array(conf_list).max()\n",
    "    elif conf_type in ['box_and_model_avg', 'absent_model_aware_avg']:\n",
    "        box[1] = conf / len(boxes)\n",
    "    box[2] = w\n",
    "    box[3] = -1 # model index field is retained for consistensy but is not used.\n",
    "    box[4:] /= conf\n",
    "    return box\n",
    "\n",
    "\n",
    "def find_matching_box_quickly(boxes_list, new_box, match_iou):\n",
    "    \"\"\" \n",
    "        Reimplementation of find_matching_box with numpy instead of loops. Gives significant speed up for larger arrays\n",
    "        (~100x). This was previously the bottleneck since the function is called for every entry in the array.\n",
    "\n",
    "        boxes_list: shape: (N, label, score, weight, model index, x, y)\n",
    "        new_box: shape: (label, score, weight, model index, x, y)\n",
    "    \"\"\"\n",
    "    def bb_iou_array(boxes, new_box):\n",
    "        '''\n",
    "        boxes: shape: (N, x, y)\n",
    "        new_box: shape: (x, y)\n",
    "        '''\n",
    "        # bb interesection over union\n",
    "        x_min = np.minimum(boxes[:, 0], new_box[0])\n",
    "        x_max = np.maximum(boxes[:, 0], new_box[0])\n",
    "        y_min = np.minimum(boxes[:, 1], new_box[1])+1\n",
    "        y_max = np.maximum(boxes[:, 1], new_box[1])+1\n",
    "\n",
    "        iou = np.maximum(0, (y_min-x_max)/(y_max-x_min))\n",
    "\n",
    "        return iou\n",
    "\n",
    "    if boxes_list.shape[0] == 0:\n",
    "        return -1, match_iou\n",
    "\n",
    "    # boxes = np.array(boxes_list)\n",
    "    boxes = boxes_list\n",
    "\n",
    "    ious = bb_iou_array(boxes[:, 4:], new_box[4:])\n",
    "\n",
    "    ious[boxes[:, 0] != new_box[0]] = -1\n",
    "\n",
    "    best_idx = np.argmax(ious)\n",
    "    best_iou = ious[best_idx]\n",
    "\n",
    "    if best_iou <= match_iou:\n",
    "        best_iou = match_iou\n",
    "        best_idx = -1\n",
    "\n",
    "    return best_idx, best_iou\n",
    "\n",
    "\n",
    "def weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=None, iou_thr=0.55, skip_box_thr=0.0, conf_type='avg', allows_overflow=False):\n",
    "    '''\n",
    "    :param boxes_list: list of boxes predictions from each model, each box is 2 numbers.\n",
    "     It has 3 dimensions (models_number, model_preds, 2)\n",
    "     Order of boxes: x, y.\n",
    "    :param scores_list: list of scores for each model\n",
    "    :param labels_list: list of labels for each model\n",
    "    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n",
    "    :param iou_thr: IoU value for boxes to be a match\n",
    "    :param skip_box_thr: exclude boxes with score lower than this variable\n",
    "    :param conf_type: how to calculate confidence in weighted boxes. 'avg': average value, 'max': maximum value, 'box_and_model_avg': box and model wise hybrid weighted average, 'absent_model_aware_avg': weighted average that takes into account the absent model.\n",
    "    :param allows_overflow: false if we want confidence score not exceed 1.0\n",
    "\n",
    "    :return: boxes: boxes coordinates (Order of boxes: x, y).\n",
    "    :return: scores: confidence scores\n",
    "    :return: labels: boxes labels\n",
    "    '''\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(boxes_list))\n",
    "    if len(weights) != len(boxes_list):\n",
    "        print('Warning: incorrect number of weights {}. Must be: {}. Set weights equal to 1.'.format(len(weights), len(boxes_list)))\n",
    "        weights = np.ones(len(boxes_list))\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    if conf_type not in ['avg', 'max', 'box_and_model_avg', 'absent_model_aware_avg']:\n",
    "        print('Unknown conf_type: {}. Must be \"avg\", \"max\" or \"box_and_model_avg\", or \"absent_model_aware_avg\"'.format(conf_type))\n",
    "        exit()\n",
    "\n",
    "    filtered_boxes = prefilter_boxes(boxes_list, scores_list, labels_list, weights, skip_box_thr)\n",
    "    if len(filtered_boxes) == 0:\n",
    "        return np.zeros((0, 2)), np.zeros((0,)), np.zeros((0,))\n",
    "\n",
    "    overall_boxes = []\n",
    "    for label in filtered_boxes:\n",
    "        boxes = filtered_boxes[label]\n",
    "        new_boxes = []\n",
    "        weighted_boxes = np.empty((0,6)) ## [label, score, weight, model index, x, y]\n",
    "        # Clusterize boxes\n",
    "        for j in range(0, len(boxes)):\n",
    "            index, best_iou = find_matching_box_quickly(weighted_boxes, boxes[j], iou_thr)\n",
    "\n",
    "            if index != -1:\n",
    "                new_boxes[index].append(boxes[j])\n",
    "                weighted_boxes[index] = get_weighted_box(new_boxes[index], conf_type)\n",
    "            else:\n",
    "                new_boxes.append([boxes[j].copy()])\n",
    "                weighted_boxes = np.vstack((weighted_boxes, boxes[j].copy()))\n",
    "\n",
    "        # Rescale confidence based on number of models and boxes\n",
    "        for i in range(len(new_boxes)):\n",
    "            clustered_boxes = np.array(new_boxes[i])\n",
    "            if conf_type == 'box_and_model_avg':\n",
    "                # weighted average for boxes\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / weighted_boxes[i, 2]\n",
    "                # identify unique model index by model index column\n",
    "                _, idx = np.unique(clustered_boxes[:, 3], return_index=True)\n",
    "                # rescale by unique model weights\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] *  clustered_boxes[idx, 2].sum() / weights.sum()\n",
    "            elif conf_type == 'absent_model_aware_avg':\n",
    "                # get unique model index in the cluster\n",
    "                models = np.unique(clustered_boxes[:, 3]).astype(int)\n",
    "                # create a mask to get unused model weights\n",
    "                mask = np.ones(len(weights), dtype=bool)\n",
    "                mask[models] = False\n",
    "                # absent model aware weighted average\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / (weighted_boxes[i, 2] + weights[mask].sum())\n",
    "            elif conf_type == 'max':\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] / weights.max()\n",
    "            elif not allows_overflow:\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * min(len(weights), len(clustered_boxes)) / weights.sum()\n",
    "            else:\n",
    "                weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / weights.sum()\n",
    "        \n",
    "        # REQUIRE BBOX TO BE PREDICTED BY AT LEAST 2 MODELS\n",
    "        #for i in range(len(new_boxes)):\n",
    "        #    clustered_boxes = np.array(new_boxes[i])\n",
    "        #    if len(np.unique(clustered_boxes[:, 3])) > 1:\n",
    "        #        overall_boxes.append(weighted_boxes[i])\n",
    "                \n",
    "        overall_boxes.append(weighted_boxes) # NOT NEEDED FOR \"REQUIRE TWO MODELS\" ABOVE\n",
    "    overall_boxes = np.concatenate(overall_boxes, axis=0) # NOT NEEDED FOR \"REQUIRE TWO MODELS\" ABOVE\n",
    "    #overall_boxes = np.array(overall_boxes) # NEEDED FOR \"REQUIRE TWO MODELS\" ABOVE\n",
    "    overall_boxes = overall_boxes[overall_boxes[:, 1].argsort()[::-1]]\n",
    "    boxes = overall_boxes[:, 4:]\n",
    "    scores = overall_boxes[:, 1]\n",
    "    labels = overall_boxes[:, 0]\n",
    "    return boxes, scores, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c2691",
   "metadata": {
    "papermill": {
     "duration": 0.012874,
     "end_time": "2022-03-17T03:28:44.786862",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.773988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Our NLP models trained on NER task\n",
    "Here is a summary of our models and their individual performance:\n",
    "\n",
    "| Hugging Face Model | CV | Public LB | Private LB | special |\n",
    "| --- | --- | | | |\n",
    "| microsoft/deberta-large | 706 | 710 | 721 | trained with 100% train data|\n",
    "| microsoft/deberta-large | 699 | 706 | 719 | add lstm, add jaccard loss |\n",
    "| microsoft/deberta-v3-large | 705 | |  | [convert slow tokenizer to fast][9] |\n",
    "| microsoft/deberta-xlarge | 708 | 704 | 713 | |\n",
    "| microsoft/deberta-v2-xlarge | 702 |  |  | [convert slow tokenizer to fast][9] |\n",
    "| allenai/longformer-large-4096 | 702 | 705 | 716 | add lstm head|\n",
    "| [LSG converted roberta][1] | 703 | 702 | 714 | convert 512 roberta to 1536 |\n",
    "| funnel-transformer/large | 688 | 689 | 708 |\n",
    "| google/bigbird-roberta-base | 675 | 676 | 692 | train 1024 infer 1024 |\n",
    "| uw-madison/yoso-4096 | 652 | 655 | 668 | lsh_backward=False |\n",
    "\n",
    "[1]: https://github.com/ccdv-ai/convert_checkpoint_to_lsg\n",
    "[3]: https://github.com/ZFTurbo/Weighted-Boxes-Fusion\n",
    "[9]: https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b332b609",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-03-17T03:28:44.821564Z",
     "iopub.status.busy": "2022-03-17T03:28:44.820755Z",
     "iopub.status.idle": "2022-03-17T03:42:56.262703Z",
     "shell.execute_reply": "2022-03-17T03:42:56.262194Z"
    },
    "papermill": {
     "duration": 851.463018,
     "end_time": "2022-03-17T03:42:56.262849",
     "exception": false,
     "start_time": "2022-03-17T03:28:44.799831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> using span token mean...\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\r\n",
      "  \"num_layers={}\".format(dropout, num_layers))\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.95it/s]\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\r\n",
      "  \"num_layers={}\".format(dropout, num_layers))\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.98it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.97it/s]\r\n",
      "==> using -1 in offset mapping...\r\n",
      "==> using span token mean...\r\n",
      "==> Using Chris BIO\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.13it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.09it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.11it/s]\r\n",
      "==> using span token mean...\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.15it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.13it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.13it/s]\r\n",
      "==> using span token mean...\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.64it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.63it/s]\r\n",
      "==> using -1 in offset mapping...\r\n",
      "==> using span token mean...\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.57it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.58it/s]\r\n",
      "==> using span token mean...\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.01it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.01it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.01it/s]\r\n",
      "==> using span token mean...\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  7.99it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  7.88it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  7.96it/s]\r\n",
      "==> using span token mean...\r\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  8.68it/s]\r\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  8.65it/s]\r\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  8.32it/s]\r\n",
      "==> using span token mean...\r\n",
      "==> Using Chris BIO\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 30.58it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 30.64it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 28.56it/s]\r\n",
      "Processing ./transformers-4.16.0\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.16.0-py3-none-any.whl size=3544999 sha256=d49099aff38cdf2662328bbe26332a1a08781189dda2893d862adf42cb06a3a6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/86/51/d3b089ebcc2628dc7be2961685253f8e0222a106a5cfd061ee\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.15.0\r\n",
      "    Uninstalling transformers-4.15.0:\r\n",
      "      Successfully uninstalled transformers-4.15.0\r\n",
      "Successfully installed transformers-4.16.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "==> using span token mean...\r\n",
      "Ignored unknown kwarg option direction\r\n",
      "Ignored unknown kwarg option direction\r\n",
      "Ignored unknown kwarg option direction\r\n",
      "Ignored unknown kwarg option direction\r\n",
      "Ignored unknown kwarg option direction\r\n",
      "Ignored unknown kwarg option direction\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 18.13it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 18.10it/s]\r\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 17.97it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python generate_preds.py --model_paths ../input/longformerwithbilstmhead/aug-longformer-large-4096-f0/checkpoint-5500 \\\n",
    "                                        ../input/longformerwithbilstmhead/aug-longformer-large-4096-f2/checkpoint-7500 \\\n",
    "                                        ../input/longformerwithbilstmhead/aug-longformer-large-4096-f5/checkpoint-6000 \\\n",
    "                            --save_name longformerwithlstm --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths ../input/deberta-large-100/fold0 \\\n",
    "                                        ../input/deberta-large-100/fold1 \\\n",
    "                                        ../input/deberta-large-100/fold2 \\\n",
    "                            --save_name debertal_chris --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths ../input/deberta-large-v2/deberta-large-v2100-f0/checkpoint-10500 \\\n",
    "                                        ../input/deberta-large-v2/deberta-large-v2101-f1/checkpoint-11500 \\\n",
    "                                        ../input/deberta-large-v2/deberta-large-v2102-f2/checkpoint-8500 \\\n",
    "                            --save_name debertal --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths ../input/deberta-xlarge-1536/deberta-xlarge-v8004-f4/checkpoint-14000 \\\n",
    "                                        ../input/deberta-xlarge-1536/deberta-xlarge-v4005-f5/checkpoint-13000 \\\n",
    "                            --save_name debertaxl --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths ../input/deberta-v2-xlarge/deberta-v2-xlarge-v6000-f0/checkpoint-7500 \\\n",
    "                                        ../input/deberta-v2-xlarge/deberta-v2-xlarge-v6003-f3/checkpoint-9000 \\\n",
    "                            --save_name deberta_v2 --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths ../input/deberta-lstm-jaccard/jcl-deberta-large-f1/checkpoint-4500 \\\n",
    "                                        ../input/deberta-lstm-jaccard/jcl-deberta-large-f2/checkpoint-5000 \\\n",
    "                                        ../input/deberta-lstm-jaccard/jcl-deberta-large-f3/checkpoint-3500 \\\n",
    "                            --save_name debertawithlstm --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths  ../input/funnel-large-6folds/large-v628-f1/checkpoint-11500 \\\n",
    "                                         ../input/funnel-large-6folds/large-v627-f3/checkpoint-11000 \\\n",
    "                                         ../input/funnel-large-6folds/large-v623-f4/checkpoint-10500 \\\n",
    "                            --save_name funnel --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths  ../input/auglsgrobertalarge/lsg-roberta-large-0/checkpoint-6750 \\\n",
    "                                         ../input/auglsgrobertalarge/lsg-roberta-large-2/checkpoint-7000 \\\n",
    "                                         ../input/auglsgrobertalarge/lsg-roberta-large-5/checkpoint-6500 \\\n",
    "                             --save_name lsg --max_len 1536\n",
    "\n",
    "!python generate_preds.py --model_paths  ../input/bird-base/fold1 \\\n",
    "                                         ../input/bird-base/fold3 \\\n",
    "                                         ../input/bird-base/fold5 \\\n",
    "                            --save_name bigbird_base_chris --max_len 1024\n",
    "\n",
    "!python generate_preds.py --model_paths  ../input/feedbackyoso/yoso-4096-0/checkpoint-12500 \\\n",
    "                                         ../input/feedbackyoso/yoso-4096-2/checkpoint-11000 \\\n",
    "                                         ../input/feedbackyoso/yoso-4096-4/checkpoint-12500 \\\n",
    "                            --save_name yoso --max_len 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68743c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:42:56.362439Z",
     "iopub.status.busy": "2022-03-17T03:42:56.354304Z",
     "iopub.status.idle": "2022-03-17T03:42:56.410672Z",
     "shell.execute_reply": "2022-03-17T03:42:56.410100Z",
     "shell.execute_reply.started": "2022-02-23T10:00:32.487604Z"
    },
    "papermill": {
     "duration": 0.103289,
     "end_time": "2022-03-17T03:42:56.410811",
     "exception": false,
     "start_time": "2022-03-17T03:42:56.307522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np, os\n",
    "\n",
    "longformer_csv = pd.read_csv(\"longformerwithlstm.csv\").dropna()\n",
    "deberta_v3_csv = pd.read_csv(\"debertawithlstm.csv\").dropna()\n",
    "deberta_v2_csv = pd.read_csv(\"deberta_v2.csv\").dropna()\n",
    "debertaxl_csv = pd.read_csv(\"debertaxl.csv\").dropna()\n",
    "debertal_chris_csv = pd.read_csv(\"debertal_chris.csv\").dropna()\n",
    "debertal_csv = pd.read_csv(\"debertal.csv\").dropna()\n",
    "yoso_csv = pd.read_csv(\"yoso.csv\").dropna()\n",
    "funnel_csv = pd.read_csv(\"funnel.csv\").dropna()\n",
    "bird_base_chris_csv = pd.read_csv(\"bigbird_base_chris.csv\").dropna()\n",
    "lsg_csv = pd.read_csv(\"lsg.csv\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197bc11b",
   "metadata": {
    "papermill": {
     "duration": 0.043558,
     "end_time": "2022-03-17T03:42:56.498866",
     "exception": false,
     "start_time": "2022-03-17T03:42:56.455308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble Models with WBF\n",
    "We will now read in the 10 submission files generated above and apply WBF to ensemble them. After applying WBF, it is important to remove predictions with confidence score below threshold. This is explained [here][1]. \n",
    "\n",
    "If only 1 model out of 10 models makes a certain span prediction, that prediction will still be present in WBF's outcome. However that prediction will have a very low confidence score because that model's confidence score will be averaged with 9 zero confidence scores. We found optimal confidence scores per class by analyzing our CV OOF score. For each class, we vary the threshold and compute the corresponding class metric score.\n",
    "\n",
    "![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Mar-2022/conf_scores.png)\n",
    "\n",
    "[1]: https://www.kaggle.com/c/tensorflow-great-barrier-reef/discussion/307609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb3aeca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:42:56.591432Z",
     "iopub.status.busy": "2022-03-17T03:42:56.590815Z",
     "iopub.status.idle": "2022-03-17T03:42:56.593903Z",
     "shell.execute_reply": "2022-03-17T03:42:56.593429Z"
    },
    "papermill": {
     "duration": 0.051206,
     "end_time": "2022-03-17T03:42:56.594013",
     "exception": false,
     "start_time": "2022-03-17T03:42:56.542807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_DIR = '../input/feedback-prize-2021/test/'\n",
    "test_files = os.listdir(TEST_DIR)\n",
    "v_ids = [f.replace('.txt','') for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c10d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:42:56.696826Z",
     "iopub.status.busy": "2022-03-17T03:42:56.696036Z",
     "iopub.status.idle": "2022-03-17T03:42:56.698423Z",
     "shell.execute_reply": "2022-03-17T03:42:56.697914Z"
    },
    "papermill": {
     "duration": 0.060844,
     "end_time": "2022-03-17T03:42:56.698558",
     "exception": false,
     "start_time": "2022-03-17T03:42:56.637714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class_to_label = {\n",
    "    'Claim': 0, \n",
    "    'Evidence': 1, \n",
    "    'Lead':2, \n",
    "    'Position':3, \n",
    "    'Concluding Statement':4,\n",
    "    'Counterclaim':5, \n",
    "    'Rebuttal':6\n",
    "}\n",
    "\n",
    "# Threshold found from CV\n",
    "label_to_threshold = {\n",
    "    0 : 0.275, #Claim\n",
    "    1 : 0.375, #Evidence\n",
    "    2 : 0.325, #Lead\n",
    "    3 : 0.325, #Position\n",
    "    4 : 0.4, #Concluding Statement\n",
    "    5 : 0.275, #Counterclaim\n",
    "    6 : 0.275 #Rebuttal\n",
    "}\n",
    "\n",
    "label_to_class = {v:k for k, v in class_to_label.items()}\n",
    "\n",
    "def preprocess_for_wbf(df_list):\n",
    "    boxes_list=[]\n",
    "    scores_list=[]\n",
    "    labels_list=[]\n",
    "    \n",
    "    for df in df_list:\n",
    "        scores_list.append(df['scores'].values.tolist())\n",
    "        labels_list.append(df['class'].map(class_to_label).values.tolist())\n",
    "        predictionstring = df.predictionstring.str.split().values\n",
    "        df_box_list = []\n",
    "        for bb in predictionstring:\n",
    "            df_box_list.append([int(bb[0]), int(bb[-1])])\n",
    "        boxes_list.append(df_box_list)\n",
    "    return boxes_list, scores_list, labels_list\n",
    "\n",
    "def postprocess_for_wbf(idx, boxes_list, scores_list, labels_list):\n",
    "    preds = []\n",
    "    for box, score, label in zip(boxes_list, scores_list, labels_list):\n",
    "        if score > label_to_threshold[label]: \n",
    "            start = math.ceil(box[0])\n",
    "            end = int(box[1])\n",
    "            preds.append((idx, label_to_class[label], ' '.join([str(x) for x in range(start, end+1)])))\n",
    "    return preds\n",
    "\n",
    "def generate_wbf_for_id(i):\n",
    "    df1 = debertal_csv[debertal_csv['id']==i]\n",
    "    df2 = debertal_chris_csv[debertal_chris_csv['id']==i]\n",
    "    df3 = funnel_csv[funnel_csv['id']==i]\n",
    "    df4 = debertaxl_csv[debertaxl_csv['id']==i]\n",
    "    df5 = longformer_csv[longformer_csv['id']==i]\n",
    "    df6 = deberta_v3_csv[deberta_v3_csv['id']==i]\n",
    "    df7 = yoso_csv[yoso_csv['id']==i]\n",
    "    df8 = bird_base_chris_csv[bird_base_chris_csv['id']==i]\n",
    "    df9 = lsg_csv[lsg_csv['id']==i]\n",
    "    df10 = deberta_v2_csv[deberta_v2_csv['id']==i]\n",
    "    \n",
    "    boxes_list, scores_list, labels_list = preprocess_for_wbf([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10])\n",
    "    nboxes_list, nscores_list, nlabels_list = weighted_boxes_fusion(boxes_list, scores_list, labels_list, iou_thr=0.33, conf_type='avg')\n",
    "\n",
    "    return postprocess_for_wbf(i, nboxes_list, nscores_list, nlabels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496ee0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:42:56.792086Z",
     "iopub.status.busy": "2022-03-17T03:42:56.790657Z",
     "iopub.status.idle": "2022-03-17T03:42:56.925897Z",
     "shell.execute_reply": "2022-03-17T03:42:56.926483Z"
    },
    "papermill": {
     "duration": 0.184179,
     "end_time": "2022-03-17T03:42:56.926649",
     "exception": false,
     "start_time": "2022-03-17T03:42:56.742470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "with mp.Pool(2) as p:\n",
    "    list_of_list = p.map(generate_wbf_for_id, v_ids)\n",
    "\n",
    "preds = [x for sub_list in list_of_list for x in sub_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36b2d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:42:57.020741Z",
     "iopub.status.busy": "2022-03-17T03:42:57.019944Z",
     "iopub.status.idle": "2022-03-17T03:42:57.026443Z",
     "shell.execute_reply": "2022-03-17T03:42:57.026019Z"
    },
    "papermill": {
     "duration": 0.055502,
     "end_time": "2022-03-17T03:42:57.026576",
     "exception": false,
     "start_time": "2022-03-17T03:42:56.971074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(preds)\n",
    "sub.columns = [\"id\", \"class\", \"predictionstring\"]\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b688f3a",
   "metadata": {
    "papermill": {
     "duration": 0.043973,
     "end_time": "2022-03-17T03:42:57.114862",
     "exception": false,
     "start_time": "2022-03-17T03:42:57.070889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualize Test Predictions\n",
    "Below we visualize the test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b551731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:42:57.214146Z",
     "iopub.status.busy": "2022-03-17T03:42:57.213629Z",
     "iopub.status.idle": "2022-03-17T03:43:04.062985Z",
     "shell.execute_reply": "2022-03-17T03:43:04.062060Z"
    },
    "papermill": {
     "duration": 6.904339,
     "end_time": "2022-03-17T03:43:04.063126",
     "exception": false,
     "start_time": "2022-03-17T03:42:57.158787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from spacy import displacy\n",
    "\n",
    "test_path = Path('../input/feedback-prize-2021/test')\n",
    "\n",
    "colors = {\n",
    "            'Lead': '#8000ff',\n",
    "            'Position': '#2b7ff6',\n",
    "            'Evidence': '#2adddd',\n",
    "            'Claim': '#80ffb4',\n",
    "            'Concluding Statement': 'd4dd80',\n",
    "            'Counterclaim': '#ff8042',\n",
    "            'Rebuttal': '#ff0000',\n",
    "            'Other': '#007f00',\n",
    "         }\n",
    "\n",
    "def get_test_text(ids):\n",
    "    with open(test_path/f'{ids}.txt', 'r') as file: data = file.read()\n",
    "    return data\n",
    "\n",
    "def visualize(df):\n",
    "    ids = df[\"id\"].unique()\n",
    "    for i in range(len(ids)):\n",
    "        ents = []\n",
    "        example = ids[i]\n",
    "        curr_df = df[df[\"id\"]==example]\n",
    "        text = \" \".join(get_test_text(example).split())\n",
    "        splitted_text = text.split()\n",
    "        for i, row in curr_df.iterrows():\n",
    "            predictionstring = row['predictionstring']\n",
    "            predictionstring = predictionstring.split()\n",
    "            wstart = int(predictionstring[0])\n",
    "            wend = int(predictionstring[-1])\n",
    "            ents.append({\n",
    "                             'start': len(\" \".join(splitted_text[:wstart])), \n",
    "                             'end': len(\" \".join(splitted_text[:wend+1])), \n",
    "                             'label': row['class']\n",
    "                        })\n",
    "        ents = sorted(ents, key = lambda i: i['start'])\n",
    "\n",
    "        doc2 = {\n",
    "            \"text\": text,\n",
    "            \"ents\": ents,\n",
    "            \"title\": example\n",
    "        }\n",
    "\n",
    "        options = {\"ents\": ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement', 'Counterclaim', 'Rebuttal'], \"colors\": colors}\n",
    "        displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4a1cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-17T03:43:04.229135Z",
     "iopub.status.busy": "2022-03-17T03:43:04.228371Z",
     "iopub.status.idle": "2022-03-17T03:43:04.278223Z",
     "shell.execute_reply": "2022-03-17T03:43:04.277076Z"
    },
    "papermill": {
     "duration": 0.138851,
     "end_time": "2022-03-17T03:43:04.278509",
     "exception": false,
     "start_time": "2022-03-17T03:43:04.139658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">0FB0700DAF44</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    During a group project, have you ever asked a group member about adding or replacing something? Or, when you were studying for a math test, did you ever ask your parents or sibling about different\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n",
       "</mark>\n",
       " ways to tackle a certain problem?\n",
       "<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Asking for other's opinions is especially beneficial as it allows for\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     it allows for an individual to receive a variety of different views towards a given topic. Likewise,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     being diverse and asking many people for their opinions allows one to understand how most people percieve something.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     people percieve something. This is especially important as knowing multiple opinions can allow someone to take those views into account and sway themseleves to the general audience.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " Knowing different people's opinion can be beneficial in a variety of situations. First\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     and foremost, a great example about how knowing other's opinions is helpful is when someone is making the choice between smoking or refraining from smoking. A student can watch on a TV channel that smoking is bad, and can damage their internal organs. However, on another channel, the student can find advertisements about the most addicting smoking device that can release the most dopomine in the brain, all the while not severly harming people's lungs. This student will\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     how knowing other's opinions is helpful is when someone is making the choice between smoking or refraining from smoking. A student can watch on a TV channel that smoking is bad, and can damage their internal organs. However, on another channel, the student can find advertisements about the most addicting smoking device that can release the most dopomine in the brain, all the while not severly harming people's lungs. This student will receive a variety of different views and opinions on a certain topic, which allows them to make the best educated choice or decision based on how they interpret what they saw. Similarily, a student can be told from his fellow classmates that smoking is fun, joyful, and makes them happy. However, if the student asks a local doctor, they will be informed differently. A doctor will most likely tell them that smoking, although seeming harmless at first, can lead to serious long term consequences. If the student asks both his friends and his doctors, he is able to use his\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Similarily, a student can be told from his fellow classmates that smoking is fun, joyful, and makes them happy. However, if the student asks a local doctor, they will be informed differently. A doctor will most likely tell them that smoking, although seeming harmless at first, can lead to serious long term consequences. If the student asks both his\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " friends and his doctors, he is able to use his judgemental skills to determing which choice will be best for him in the long run. Furthermore,\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     asking for multiple opinions can benifit during competitions for a position slot, as cadidates needs to make decisions on what they need to say or\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     or do. For example, it can be helpful in situations like elections, both for the U.S. or simply in school. If a student is running for a position in office to represent his/her school, he/she can ask a widespread and diverse audience. First, asking other students is their best bet to obtaining information. Other students can inform him/her about what they want, like better water fountains, recess, or healthier food. Then, the student running can make changes to the way they run for the election, and on his/her speech, take a different approach. In addition, if the student running asks an adult, they will get to know a more realistic way the school can be improved. Since a student, even as a student officer, isn't able to make a significant change to a school, they can inform the school board about ways to make the school better. If someone is running for the president of the United States, a similar approach can be taken. First, they can ask the people, on social media or in speeches, about positive ways to reform our country. After the candidate receives the opinion of general audiences, they can campaign differently to match the view of those voting. All in all, asking for the opinion of multiple different people can set the candidate apart from\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " others.\n",
       "<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Many people only ask one type of audience for their opinion. Having only one opinion can lead to negative consequences, such as making the wrong choices related to health or education, as only one audience is adressed into making a decision. Therefore, asking multiple different people who have different backgrounds is essential to making the best choices in life. Conclusively, knowing multiple opinions on a certain matter can evidently lead to better results for\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n",
       "</mark>\n",
       " individuals.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">D72CB1C11673</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Making choices in life can be very difficult. People often ask for advice when they can not decide on one thing. It's always good to ask others for their advice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n",
       "</mark>\n",
       " when making a choice. When you have\n",
       "<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     multiple opinions you have the ability to make the best choice for yourself. Seeking multiple opinions can help a person make a better choice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n",
       "</mark>\n",
       " because\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     it can decrease stress levels,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     levels, a great chance to learn something new, can be\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     be very helpful and beneficial. To\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " begin with, Seeking information from more than one person can decrease stress levels.\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     When making a decision there is a chance that you can become very stressed and overwhelmed. Being stressed can cause a person to give up on what they are doing. Having multiple opinions from people can make choosing an option less difficult and more easier. The information that you receive from others may have a special meaning in the future. Other peoples opinion can make a person feel confident in making the right\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " choice. When\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     you ask other people for their opinion you can also learn many new\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " things.\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Everyone is different and may have more experience than you. Seeking other peoples opinion can cause you to gain a new skill or lesson. For example, someones advice could teach you how to do something the correct way. Many people are very different and have experience different things in life. Seeking advice from others can teach you a lot. We all learn from our mistakes in life, by sharing your past experiences you may prevent someone else from making the same\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " mistake. Seeking\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     others opinion can be very helpful and\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " beneficial. Taking\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     other peoples advice and doing what they say may lead to a great outcome. When you receive other opinions whether they are good or bad you will be able to look at them from a different point of view. For example, When a group of people give you advice on yourself, you then know how they look at you as a person. Everyone looks at certain things from a different prospective. How someone else looks at it may be how its supposed to be viewed in life.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " In conclusion,\n",
       "<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     You can learn from others experiences by seeking the advice that someone give you. Making decisions can cause stress on a person. Relating to someones advice may higher your self-esteem because you no longer feel left out. Ask others for advice when making a difficult decision. When you seek others opinion more opportunities are available fro yourself.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">18409261F5C2</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    80% of Americans believe seeking multiple opinions can help them make better choices, and for good reason. Studies have shown the average Americans faring far better in their lives compared to their counterparts because they are listening to other's advice. There are also many myths that have the moral of listening to other people's opinions. For example, Perseus got his achievement of slaying a gorgon because he listened to the Oracle. Another example I have is the fable of Osiris, in which Osiris listens to Sekhmet and becomes the king of he underworld. In all of these stories, the hero listens to other people, and benefited from the people around them being more knowledgeable, more experienced, and giving\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n",
       "</mark>\n",
       " the hero more choices to consider. Therefore,\n",
       "<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     I believe listening to other's advice can help someone make a better choice because they\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     they have more experience compared to you, know the\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     the pros and cons of your choice,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " and\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     gives you multiple perspectives to deliberate over.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " For example, let\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     us talk about the anecdote of little Generic_Name, whose life was changed forever by listening to a person who has more experience than him. As a young lad, little Generic_Name always dreamed of becoming a soldier, because he admired his mother who fought in WW2. But Generic_Name's mother, who lived through the inhospitable battlefield, didnt want her child to follow her path. As a result, she talked to him about the hardships that plagued her when she was a soldier, and successfully changed his mind. Thanks to Generic_Name's mother changing little Generic_Name's mind, He became a successful and joyous doctor who saves countless of lives every day. If Generic_Name's mother hadn't been a soldier who has lived through the darkest depths of hell called the battlefield, then she wouldn't have been able to change little Generic_Name's mind, and he may have had his life cut short. Another story we can talk about is the story of little Generic_Name, who always wanted to be a magician. Generic_Name always fantasizes about being on stage, listening to the crowds wild applause as she entertains them, and thankfully, her father is there to fulfill her fantasies. Thanks to Generic_Name's father being a renowned magician, he had the connections and knew the tricks that could excite the crowd. As a result, Generic_Name became the greatest magician of that generation. If Generic_Name's father wasnt a magician who had walked the path Generic_Name was planning to walk, then she wouldnt have been able to reach the heights she was reaching right now.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " Therefore, I\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     believe that listening to people who have more experiences compared to you an help you make a better judgment.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Another anecdote we can talk about is the anecdote of Generic_Name, a menacing ancient man who knew the pros and cons of doing drugs. As Generic_Name was walking the streets of New Jersey, he saw a group about to eat drugs. Generic_Name walked towards the group, and he latched his hand on to the nearest person's, and stopped the person from doing some drugs. Generic_Name reprimanded the group about doing drugs, and thanks to his menacing presence, the group stopped downing some pills. Thanks to the effort of Generic_Name who lectured the group about the pros and cons of eating drugs, the group was saved from the evil influences of drugs, and grew up to be a group who fought against drug use. If Generic_Name wasn't telling the group about the pros and cons of drugs, they would have eaten it and fallen into a path which is very hard to recover from. But thankfully, Generic_Name saved them from that despairing future. Another anecdote I want to talk about is the story of Generic_Name, who wanted o be doctor. Generic_Name didn't know much about being a doctor, except that she wanted to be one, so her grandfather talked with her about her choice. As they discussed the pros and cons of being a doctor, Generic_Name grew more knowledgeable about the choice she is going to make. As a result, Generic_Name is much more firm in her beliefs about being a doctor, and grew up to be an amazing doctor. If she didnt' talk with her grandfather about her choice, she would have made an uniformed decision that likely would have ruined her life.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " Therefore,\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     I believe that listening to other's advice can help someone make a better choice by giving them the pros and cons of their choice.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " One anecdote I want to talk about\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     is the story of Generic_Name, who wanted to be a lawyer because her friend's advised her. She was steadfast in her beliefs as she always enjoyed rules and regulations, until her mother gave her a new perspective to mull over. She told her to aim to become a supreme dragon, rather than being a struggling python. As a result, Generic_Name aimed to be a supreme judge, and she became one at the age of 65. Thanks to her mother giving her better advice, She became a star that outshone other's in the world of law. Another anecdote I want to talk about is the story of Generic_Name whose life changed thanks to a fateful encounter that changed his life. Generic_Name felt forced to be a fashion designer, as it was a family tradition. He didn't know what to do, until he heard his grandmother talking with his family about animal cloning. He grew interested in animal cloning and researched it until he considered it a his future career. As a result, he grew up to become a biologist, doing something he loves. If it wasn't for his grandmother telling Generic_Name's family members about animal cloning, he wouldn't have even considered it, and may have grown to be a nihilistic person who isn't able to change his fate of suffering.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " Therefore, I believe seeking multiple opinions can help someone make a better choice because it can give them multiple perspectives to consider. In conclusion, little\n",
       "<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Generic_Name, Generic_Name, Generic_Name, and many more changed their entire lives by listening to other people. If they didn't seek other's advice, they would have fallen into a path that would not allow their potential to bloom. But, thankfully, they chose to listen to other people. As a result, they grew to be figures that were respected around the world. Therefore, I in believe seeking multiple opinions.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">DF920E0A7337</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Have you ever asked more than one person for help on what product to buy in a situation? Interviews are a perfect example of seeking more than one opinion. Interviews are seen on the news, in professional sports, and other places as well. There are a lot of people that can help you buy the right product as well. They can all\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n",
       "</mark>\n",
       " open you up to new ideas.\n",
       "<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     I think talking to more than one person on an opinion is a better choice because it\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     it shows you more than one option, it can\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     can change your perspective of a topic,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " and\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     it informs you about what other people enjoy.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " First, I think it shows you more than one option.\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     One opinion of a person might destroy your choice on an option rather than opening it up. The whole point of asking what is the better choice, is to make it better, not worse. You could already have the better opinion, and that person might ruin it, but more people would give you a good balance of what you need to know. Multiple opinions can stride you toward different answers. Different answers will most of the time make things go in the right direction. Its good to show variety in what you're going to pick in order to get the best choice. One opinion could be someone who isn't informed on the idea. They might not know anything about the topic and might just state a random answer. That can really throw you off if you don't get more ideas than just that one person. That can have the same effect as what I said before. That one person could mess it all up for you. All of the people you ask shows you more than what you thought was the best choice.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " Next, it\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     can change your perspective on the topic.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     One person can change your option, but it may not lead you in the right direction. That direction could make you unhappy with your choice if you are comparing a product to see which one to get. You could take that one persons advice and follow it, but it might not be the best advice you could get. Multiple people have a better chance of leading you to the right opinion. When you get the opinion of multiple people, it balances out what might be the favorite option, or what might be the better option. A lot of times, changing your opinion is for the better. You could be looking at the wrong choice, and multiple opinions might lead you to the right path. It gives new ideas and ways to look at a situation and make the right choice. It can make you change your\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " opinion. Finally, it\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     informs you about what other people enjoy.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Having more than one person's opinion might lead to an agreement with those people. You could be really stuck on a certain product you are trying to buy, and someone could save that entire situation by finding a good version of that product. You could also learn more about culture and peoples opinions in a certain area, or a certain time. Many people are different and sometimes that is based off of the environment around them, and where they grow up that could affect what a person likes. If you ask multiple people in the same area you grew up in, you should be leading yourself to the right choice. It can also lead to meeting new people, and making new friends. You could agree on an opinion and start a bond there. It all helps you on knowing not only what you like, but what a lot of other people\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " like. In conclusion,\n",
       "<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     finding more than one persons view is better because it shows more than one opinion, it can change your own opinion, and it can inform you on what other people enjoy. If you are ever interviewing people, or looking for advice from other people to make the right decision, make sure you ask multiple people and not just one person for that advice! I always ask friends, family, or other people for help and advice if I should do something or not. You've probably asked multiple people for advice as\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n",
       "</mark>\n",
       " well!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">D46BCB48440A</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    When people ask for advice,they sometimes talk to more than one person. Advice is an opinion,that's told to another person. I think advises help\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     think advises help people make better choices. Some reasons I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n",
       "</mark>\n",
       " think why advises helps is\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     keeps you safe,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     makes goal come true,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " and makes\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     changes. The\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " reason I think advises help is keeps you safe.\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     There are many dangerous people and thing in the world. That could hurt you in so many ways. When I got invited to a sixteen and up birthday party. I was so ready to go but i didnt know if i should go to the party. So i asked my mom for advice. Then she told me it wouldn't be the best idea,I could get kidnapped. I agreed with her and didn't go. That advice from my mom saved me from getting kidnapped.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " Another reason I\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     think Advises help is make goals come\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " true.\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Getting to your goal is pretty hard. But if you have someone to push you through it you can do it. When I gave up on becoming an Artist. My friend told me some advice telling I need to keep going until i reached my goal. And said she cheering for me. I felt hopeful again and happy that she there for\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " me. The last reason I\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     think advises help is makes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " changes.\n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Words are powerful and so are action. They can make things happen with multiple of them. At our school,the lunches are very unhealthy. We tell our teacher but they didn't listen. So we interview people around the school and asked them to sign a paper. Once we were done. We when over to the school board. And told them about the unhealthy lunches at schools. They agreed that schools should change their lunches to healthier lunches. And changed the lunches served a\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       " schools.\n",
       "<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Advises can be helpful or not helpful. But if it can help you then please listen to it. Don't block it out .So many people think it's useless. But it help in so many like keep you safe,make goals come true or makes changes. You can't do everything on your. Sometime it's better to ask for help.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(sub[\"id\"].unique())==5:\n",
    "    visualize(sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 870.614827,
   "end_time": "2022-03-17T03:43:07.018797",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-17T03:28:36.403970",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

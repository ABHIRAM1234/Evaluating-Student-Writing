{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea268ce",
   "metadata": {
    "papermill": {
     "duration": 0.016413,
     "end_time": "2022-03-15T15:37:41.773798",
     "exception": false,
     "start_time": "2022-03-15T15:37:41.757385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code is our ensemble cv result. If you are interested, you can change the prediction result to your own. What you need is to change your preds to preds1_mean and preds2_mean, which represent the probability that the token is the beginning and the probability of each class, Note that the order of class needs to be the same as the order of id2label. \n",
    "\n",
    "compared to https://www.kaggle.com/wht1996/feedback-two-stage-lb0-727, lgb features less lstm and pca, These features can increase about 0.001, but the speed is relatively slow, so they are deleted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff34b31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:37:41.814808Z",
     "iopub.status.busy": "2022-03-15T15:37:41.814057Z",
     "iopub.status.idle": "2022-03-15T15:37:44.705011Z",
     "shell.execute_reply": "2022-03-15T15:37:44.703720Z",
     "shell.execute_reply.started": "2022-03-15T12:44:54.1534Z"
    },
    "papermill": {
     "duration": 2.915302,
     "end_time": "2022-03-15T15:37:44.705248",
     "exception": false,
     "start_time": "2022-03-15T15:37:41.789946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "data_path = '../input/feedback-prize-2021/'\n",
    "\n",
    "train_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\n",
    "IDS = train_df.id.unique()\n",
    "\n",
    "kfold_ids = pickle.load(open('../input/feedback-two-stage-data/kfold_ids.pkl','rb'))\n",
    "\n",
    "id2label = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n",
    "             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "class CONFIG:\n",
    "    def __init__(self):\n",
    "        self.max_length = 4096\n",
    "        \n",
    "config = CONFIG() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aada8b9",
   "metadata": {
    "papermill": {
     "duration": 0.015603,
     "end_time": "2022-03-15T15:37:44.736487",
     "exception": false,
     "start_time": "2022-03-15T15:37:44.720884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### read pred data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79badda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:37:44.781424Z",
     "iopub.status.busy": "2022-03-15T15:37:44.780404Z",
     "iopub.status.idle": "2022-03-15T15:38:03.429603Z",
     "shell.execute_reply": "2022-03-15T15:38:03.430159Z",
     "shell.execute_reply.started": "2022-03-15T12:44:56.751775Z"
    },
    "papermill": {
     "duration": 18.678137,
     "end_time": "2022-03-15T15:38:03.430425",
     "exception": false,
     "start_time": "2022-03-15T15:37:44.752288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pred = pickle.load(open('../input/feedback-two-stage-data/feedback-lb704.pkl','rb'))\n",
    "data_pred = pd.DataFrame(data_pred, columns=['id', 'text', 'input_ids', 'attention_mask', 'token_label',\n",
    "       'offset_mapping', 'kfold', 'pred'])\n",
    "\n",
    "dic_off_map = data_pred[['id','offset_mapping']].set_index('id')['offset_mapping'].to_dict()\n",
    "dic_txt = data_pred[['id','text']].set_index('id')['text'].to_dict()\n",
    "\n",
    "\"\"\"\n",
    "ori class order\n",
    "{'O': 0,\n",
    " 'I-Claim': 1,\n",
    " 'I-Evidence': 2,\n",
    " 'I-Position': 3,\n",
    " 'I-Concluding Statement': 4,\n",
    " 'I-Lead': 5,\n",
    " 'I-Counterclaim': 6,\n",
    " 'I-Rebuttal': 7,\n",
    " 'B-Claim': 8,\n",
    " 'B-Evidence': 9,\n",
    " 'B-Position': 10,\n",
    " 'B-Concluding Statement': 11,\n",
    " 'B-Lead': 12,\n",
    " 'B-Counterclaim': 13,\n",
    " 'B-Rebuttal': 14}\n",
    "\"\"\"\n",
    "\n",
    "def change_label(x):\n",
    "    \"\"\"\n",
    "    change N*15 preds to N*1 + N*8 preds\n",
    "    \"\"\"\n",
    "    res1  = x[:,8:].sum(axis=1)\n",
    "    res2 = np.zeros((len(res1), 8))\n",
    "    \n",
    "    # change order, If it is in the same order as id2label, delete it\n",
    "    label_map = {0:5, 1:3, 2:2, 3:1, 4:4, 5:6, 6:7, 7:0} \n",
    "    for i in range(8):\n",
    "        if i == 7:\n",
    "            res2[:,i] = x[:,label_map[i]]\n",
    "        else:\n",
    "            res2[:,i] = x[:,[label_map[i], label_map[i]+7]].sum(axis=1)\n",
    "\n",
    "    return res1, res2\n",
    "\n",
    "preds1_mean = {}\n",
    "preds2_mean = {}\n",
    "for irow,row in data_pred.iterrows():\n",
    "    t1, t2 = change_label(row.pred)\n",
    "    preds1_mean[row.id] = t1.astype('float64')\n",
    "    preds2_mean[row.id] = t2.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e52fd",
   "metadata": {
    "papermill": {
     "duration": 0.015042,
     "end_time": "2022-03-15T15:38:03.461357",
     "exception": false,
     "start_time": "2022-03-15T15:38:03.446315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### get recall sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf0be4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:38:03.517286Z",
     "iopub.status.busy": "2022-03-15T15:38:03.506396Z",
     "iopub.status.idle": "2022-03-15T15:38:03.537636Z",
     "shell.execute_reply": "2022-03-15T15:38:03.536801Z",
     "shell.execute_reply.started": "2022-03-15T12:45:12.787173Z"
    },
    "papermill": {
     "duration": 0.06091,
     "end_time": "2022-03-15T15:38:03.537821",
     "exception": false,
     "start_time": "2022-03-15T15:38:03.476911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recall_thre = { \n",
    "    \"Lead\": 0.07,\n",
    "    \"Position\": 0.06,\n",
    "    \"Evidence\": 0.07,\n",
    "    \"Claim\": 0.06,\n",
    "    \"Concluding Statement\": 0.07,\n",
    "    \"Counterclaim\": 0.03,\n",
    "    \"Rebuttal\": 0.02,\n",
    "}\n",
    "\n",
    "L_k = {\n",
    "    \"Evidence\": 0.85,\n",
    "    \"Rebuttal\": 0.6,\n",
    "}\n",
    "\n",
    "\n",
    "def deal_predictionstring(df):\n",
    "    \"\"\"\n",
    "    select sample with high boundary threshold and \n",
    "    choice 65% length with the highest probability of the current class as a new sample\n",
    "    \"\"\"\n",
    "    new_predictionstring = []\n",
    "    new_pos_list = []\n",
    "    flag_list = []\n",
    "    thre = 0.8\n",
    "    for id, typ, pos, (start, end) in df.values:\n",
    "        flag = 0\n",
    "        L = round(max(1, (pos[1]-pos[0]+1)*0.25))\n",
    "\n",
    "        pos_left = max(0, pos[0]-L)\n",
    "        pos_right = min(len(preds1_mean[id]), pos[1]+1+L)\n",
    "        \n",
    "        if start<10:\n",
    "            left_thre = 2\n",
    "        else:\n",
    "            left_thre = max(preds1_mean[id][pos[0]], 1-preds2_mean[id][pos_left:pos[0],label2id[typ]].min())\n",
    "        \n",
    "        if pos[1] >= len(preds1_mean[id])-10:\n",
    "            right_thre=2\n",
    "        else:\n",
    "            right_thre = max(preds1_mean[id][pos[1]+1:pos_right].max(), 1-preds2_mean[id][pos[1]+1:pos_right, label2id[typ]].min())\n",
    "        \n",
    "        if left_thre>thre and right_thre>thre:\n",
    "\n",
    "            L = math.ceil((pos[1]-pos[0]+1)*L_k.get(typ, 0.65))\n",
    "\n",
    "            tmp = {}\n",
    "            for i in range(pos[0], pos[1]):\n",
    "                if i+L>pos[1]:\n",
    "                    break\n",
    "                tmp[i] = np.sum(preds2_mean[id][i:i+L+1,label2id[typ]])\n",
    "            if len(tmp)==0:\n",
    "                new_pos = pos\n",
    "            else:\n",
    "                flag = min(left_thre, right_thre)\n",
    "                new_start = max(tmp.keys(), key=lambda x:tmp[x])\n",
    "                new_pos = (new_start,new_start+L)\n",
    "\n",
    "        else:\n",
    "            new_pos = pos\n",
    "\n",
    "        off_map = dic_off_map[id]\n",
    "        txt = dic_txt[id]\n",
    "        txt_max = len(txt.split())\n",
    "\n",
    "        start_word = len(txt[:off_map[new_pos[0]][0]].split())\n",
    "\n",
    "        L = len(txt[off_map[new_pos[0]][0]:off_map[new_pos[1]][1]].split())\n",
    "        end_word = min(txt_max, start_word+L) - 1\n",
    "\n",
    "        new_predictionstring.append([start_word, end_word])\n",
    "        new_pos_list.append(new_pos)\n",
    "        flag_list.append(flag)\n",
    "        \n",
    "    df_new = df.copy()\n",
    "    df_new['pos'] = new_pos_list\n",
    "    df_new['predictionstring'] = new_predictionstring\n",
    "    df_new['flag'] = flag_list\n",
    "    \n",
    "    df_new = pd.concat([df_new, df.loc[df_new[(df_new.flag>=0.8) & (df_new.flag<0.95)].index]])\n",
    "    df_new = df_new.reset_index(drop=True)\n",
    "    df_new['flag'].fillna(0,inplace=True)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "\n",
    "def get_recall(id):\n",
    "    all_predictions = []\n",
    "\n",
    "    pred1_np = np.array(preds1_mean[id])\n",
    "    pred2_np_all = np.array(preds2_mean[id])\n",
    "\n",
    "    off_map = dic_off_map[id]\n",
    "    off_map_len = len(off_map) if off_map[-1][1] != 0 else len(off_map)-1\n",
    "    max_length = min(config.max_length, off_map_len)\n",
    "    for class_num in range(7):\n",
    "        thre = recall_thre[id2label[class_num]]\n",
    "        pred2_np = pred2_np_all[:, class_num]\n",
    "\n",
    "        i_start = 0\n",
    "        while i_start < max_length:\n",
    "            i = 0\n",
    "            if pred1_np[i_start] > thre and pred2_np[i_start:i_start+10].max() > thre: #开头\n",
    "                i = i_start + 1\n",
    "                if i>=max_length: break\n",
    "                while pred1_np[i] < (1-thre) and pred2_np[i:i+10].max() > thre: # 结束\n",
    "                    cond = any([\n",
    "                        i+1==max_length,\n",
    "                        pred1_np[i] > thre,\n",
    "                        i+1<max_length and pred2_np[i] < 0.6 and pred2_np[i] - pred2_np[i+1] > thre\n",
    "                    ])\n",
    "                    if i>i_start+1 and cond:\n",
    "                        all_predictions.append((id, id2label[class_num], [i_start, i]))\n",
    "                    i += 1\n",
    "                    if i>=max_length: break\n",
    "\n",
    "            if i != 0:\n",
    "                if i == max_length:\n",
    "                    i -=1\n",
    "\n",
    "                all_predictions.append((id, id2label[class_num], [i_start, i]))\n",
    "            i_start += 1\n",
    "                \n",
    "    df_recall = pd.DataFrame(all_predictions, columns=['id', 'class', 'pos'])\n",
    "    \n",
    "    predictionstring = []\n",
    "    for cache in df_recall.values:\n",
    "        id = cache[0]\n",
    "        pos = cache[2]\n",
    "        off_map = dic_off_map[id]\n",
    "        txt = dic_txt[id]\n",
    "        txt_max = len(txt.split())\n",
    "\n",
    "        start_word = len(txt[:off_map[pos[0]][0]].split())\n",
    "\n",
    "        L = len(txt[off_map[pos[0]][0]:off_map[pos[1]][1]].split())\n",
    "        end_word = min(txt_max, start_word+L) - 1\n",
    "\n",
    "        predictionstring.append([start_word, end_word])\n",
    "\n",
    "    df_recall['predictionstring'] = predictionstring\n",
    "\n",
    "    return deal_predictionstring(df_recall)\n",
    "#     return df_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4582dc",
   "metadata": {
    "papermill": {
     "duration": 0.015075,
     "end_time": "2022-03-15T15:38:03.568706",
     "exception": false,
     "start_time": "2022-03-15T15:38:03.553631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### lgb features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8759317f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:38:03.619581Z",
     "iopub.status.busy": "2022-03-15T15:38:03.614050Z",
     "iopub.status.idle": "2022-03-15T15:38:03.943312Z",
     "shell.execute_reply": "2022-03-15T15:38:03.942649Z",
     "shell.execute_reply.started": "2022-03-15T12:45:12.836525Z"
    },
    "papermill": {
     "duration": 0.359463,
     "end_time": "2022-03-15T15:38:03.943510",
     "exception": false,
     "start_time": "2022-03-15T15:38:03.584047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def feat_speedup(arr):\n",
    "    r_max, r_min, r_sum = -1e5,1e5,0\n",
    "    for x in arr:\n",
    "        r_max = max(r_max, x)\n",
    "        r_min = min(r_min, x)\n",
    "        r_sum += x\n",
    "    return r_max, r_min, r_sum, r_sum/len(arr)\n",
    "\n",
    "np_lin = np.linspace(0,1,7)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def sorted_quantile(array, q):\n",
    "    n = len(array)\n",
    "    index = (n - 1) * q\n",
    "    left = int(index)\n",
    "    fraction = index - left\n",
    "    right = left\n",
    "    right = right + int(fraction > 0)\n",
    "    i, j = array[left], array[right]\n",
    "    return i + (j - i) * fraction\n",
    "\n",
    "def get_percentile(array):\n",
    "    x = np.sort(array)\n",
    "    n = len(x)-1\n",
    "    return x[[int(n*t) for t in np_lin[1:-1]]]\n",
    "\n",
    "\n",
    "def tuple_map(offset_mapping,threshold):\n",
    "    paragraph_rk = []\n",
    "    rk = 0\n",
    "    last = 1\n",
    "    for token_index in offset_mapping:\n",
    "        if len(threshold) == 0:\n",
    "            paragraph_rk.append(1)\n",
    "        elif token_index[1] <= threshold[rk][1]:\n",
    "            last = max(rk+1,last)\n",
    "            paragraph_rk.append(last)\n",
    "        else: \n",
    "            last = max(rk+2,last)\n",
    "            paragraph_rk.append(last)\n",
    "            if rk + 1 < len(threshold) - 1:\n",
    "                rk += 1\n",
    "            \n",
    "    return paragraph_rk\n",
    "\n",
    "\n",
    "def get_pos_feat(text, offset_mapping):\n",
    "\n",
    "    paragraph_cnt = len(text.split('\\n\\n')) + 1\n",
    "\n",
    "    paragraph_th = [m.span() for m in re.finditer('\\n\\n',text)]\n",
    "    paragraph_rk = tuple_map(offset_mapping,paragraph_th)\n",
    "\n",
    "    paragraph_rk_r = [paragraph_cnt-rk+1 if rk!=0 else 0 for rk in paragraph_rk]\n",
    "\n",
    "    sentence_th = []\n",
    "    for i,v in enumerate([m.span() for m in re.finditer('\\n\\n|\\.|,|\\?|\\!',text)]):\n",
    "        if i == 0:\n",
    "            sentence_th.append(list(v))\n",
    "        else:\n",
    "            if v[0]==sentence_th[-1][-1]:\n",
    "                sentence_th[-1][-1] = v[-1]\n",
    "            else:\n",
    "                sentence_th.append(list(v))\n",
    "    sentence_cnt = len(sentence_th) + 1\n",
    "\n",
    "    sentence_rk = tuple_map(offset_mapping,sentence_th)\n",
    "    sentence_rk_r = [sentence_cnt-rk+1 if rk!=0 else 0 for rk in sentence_rk]\n",
    "\n",
    "    last_garagraph_cnt = 0\n",
    "    sentence_rk_of_paragraph = []\n",
    "    for i in range(len(offset_mapping)):\n",
    "        sentence_rk_of_paragraph.append(sentence_rk[i]-last_garagraph_cnt)\n",
    "        if i+1 == len(offset_mapping) or paragraph_rk[i]!=paragraph_rk[i+1]:\n",
    "            last_garagraph_cnt = sentence_rk[i]\n",
    "\n",
    "    sentence_cnt_of_paragraph = []\n",
    "    last_max = None\n",
    "    for i in range(1,len(offset_mapping)+1):\n",
    "        if i==1 or paragraph_rk[-i] != paragraph_rk[-i+1]:\n",
    "            last_max = sentence_rk_of_paragraph[-i]\n",
    "        sentence_cnt_of_paragraph.append(last_max)\n",
    "    sentence_cnt_of_paragraph = sentence_cnt_of_paragraph[::-1]\n",
    " \n",
    "    sentence_rk_r_of_paragraph = [s_cnt-rk+1 if rk!=0 else 0 for s_cnt,rk in zip(sentence_cnt_of_paragraph,sentence_rk_of_paragraph)]\n",
    "\n",
    "    return paragraph_cnt,sentence_cnt,paragraph_rk,paragraph_rk_r,sentence_rk,sentence_rk_r, \\\n",
    "            sentence_cnt_of_paragraph,sentence_rk_of_paragraph,sentence_rk_r_of_paragraph\n",
    "\n",
    "\n",
    "lgb_columns = pickle.load(open('../input/feedback-two-stage-data/lgb_columns.pkl','rb'))\n",
    "\n",
    "\n",
    "def fun_get_feat(id):\n",
    "    df_feat = []\n",
    "    \n",
    "    data_sub = get_recall(id)\n",
    "    txt = dic_txt[id]\n",
    "    off_map = dic_off_map[id]\n",
    "    txt_feat = get_pos_feat(txt, off_map)\n",
    "   \n",
    "    preds1_all = preds1_mean[id]\n",
    "    preds_type = preds2_mean[id].argmax(axis=-1)\n",
    "    \n",
    "    text_char_length = len(txt)\n",
    "    text_word_length = len(txt.split())\n",
    "    text_token_length = len(off_map)\n",
    "    for cache in data_sub.values:\n",
    "        id = cache[0]\n",
    "        typ = cache[1]\n",
    "        start, end = cache[2]\n",
    "        prediction = cache[3]\n",
    "\n",
    "        dic = {k:np.nan for k in lgb_columns}\n",
    "#         dic={'id': id}\n",
    "        dic['id'] = id\n",
    "        dic['pos'] = cache[2]\n",
    "        dic['class'] = label2id[typ]\n",
    "        dic['post_flag'] = cache[4]\n",
    "\n",
    "        dic['paragraph_cnt'] = txt_feat[0]\n",
    "        dic['sentence_cnt'] = txt_feat[1]\n",
    "        dic['paragraph_rk'] = txt_feat[2][start]\n",
    "        dic['paragraph_rk_r'] = txt_feat[3][end]\n",
    "        dic['sentence_rk'] = txt_feat[4][start]\n",
    "        dic['sentence_rk_r'] = txt_feat[5][end]\n",
    "        dic['sentence_cnt_of_paragraph'] = txt_feat[6][start]\n",
    "        dic['sentence_cnt_of_paragraph2'] = txt_feat[6][end]\n",
    "        dic['sentence_rk_of_paragraph'] = txt_feat[7][start]\n",
    "        dic['sentence_rk_r_of_paragraph'] = txt_feat[8][end]\n",
    "        dic['sub_paragraph_cnt'] = txt_feat[2][end] - txt_feat[2][start]\n",
    "        dic['sub_sentence_cnt'] = txt_feat[4][end] - txt_feat[4][start]\n",
    "\n",
    "        other_type = [t for t in range(8) if t != dic['class']]\n",
    "        preds2_all = preds2_mean[id][:, label2id[typ]]\n",
    "        preds4_all = preds2_mean[id][:, other_type].max(axis=-1)\n",
    "        preds1 = preds1_all[start:end+1]\n",
    "        preds2 = preds2_all[start:end+1]\n",
    "        preds4 = preds4_all[start:end+1]\n",
    "\n",
    "        word_length = prediction[-1] - prediction[0] + 1\n",
    "        \n",
    "        dic['L1'] = word_length\n",
    "        dic['L2'] = end - start + 1\n",
    "        dic['text_char_length'] = text_char_length\n",
    "        dic['text_word_length'] = text_word_length\n",
    "        dic['text_token_length'] = text_token_length\n",
    "\n",
    "        dic['word_start'] = prediction[0]\n",
    "        dic['word_end'] = prediction[-1]\n",
    "        dic['token_start'] = start\n",
    "        dic['token_start2'] = start / text_token_length\n",
    "        dic['token_end'] = end\n",
    "        dic['token_end2'] = text_token_length - end\n",
    "        dic['token_end3'] = end / text_token_length\n",
    "        \n",
    "        dic[f'head_preds1'] = preds1[0]\n",
    "        dic[f'head2_preds1'] = preds1_all[start-1:start+2].sum()\n",
    "        if len(preds1) > 1:\n",
    "            dic[f'tail_preds1'] = preds1[-1]\n",
    "            dic['max_preds1'], dic['min_preds1'], dic['sum_preds1'], dic['mean_preds1'] = feat_speedup(preds1[1:])\n",
    "      \n",
    "        sort_idx = preds1[1:].argsort()[::-1]\n",
    "        tmp = []\n",
    "        for i in range(5):\n",
    "            if i < len(sort_idx):\n",
    "                dic[f'other_preds1_{i}'] = preds1[1+sort_idx[i]]\n",
    "                dic[f'other_preds1_idx_{i}'] = (1+sort_idx[i])/len(preds1)\n",
    "                tmp.append(preds1[1+sort_idx[i]])\n",
    "        if len(tmp):\n",
    "            dic[f'other_preds1_mean'] = np.mean(tmp)\n",
    "\n",
    "        dic[f'head_preds2'] = preds2[0]\n",
    "        dic[f'tail_preds2'] = preds2[-1]\n",
    "        dic['max_preds2'], dic['min_preds2'], dic['sum_preds2'], dic['mean_preds2'] = feat_speedup(preds2)\n",
    "\n",
    "        dic[f'head_preds4'] = preds4[0]\n",
    "        dic[f'tail_preds4'] = preds4[-1]\n",
    "        dic['max_preds4'], dic['min_preds4'], dic['sum_preds4'], dic['mean_preds4'] = feat_speedup(preds4)\n",
    "        \n",
    "        sort_idx = preds2.argsort()\n",
    "        tmp = []\n",
    "        for i in range(5):\n",
    "            if i < len(sort_idx):\n",
    "                dic[f'other_preds2_{i}'] = preds2[sort_idx[i]]\n",
    "                dic[f'other_preds2_idx_{i}'] = (sort_idx[i])/len(preds2)\n",
    "                tmp.append(preds2[sort_idx[i]])\n",
    "        if len(tmp):\n",
    "            dic[f'other_preds2_mean'] = np.mean(tmp)\n",
    "            \n",
    "            \n",
    "        for i,ntile in enumerate([sorted_quantile(preds2,i) for i in np_lin]):\n",
    "            dic[f'preds2_trend{i}'] = ntile\n",
    "        for i,ntile in enumerate(get_percentile(preds2)):\n",
    "            dic[f'preds2_ntile{i}'] = ntile\n",
    "        for i,ntile in enumerate([sorted_quantile(preds4,i) for i in np_lin]):\n",
    "            dic[f'preds4_trend{i}'] = ntile\n",
    "        for i,ntile in enumerate(get_percentile(preds4)):\n",
    "            dic[f'preds4_ntile{i}'] = ntile\n",
    "            \n",
    "            \n",
    "        for i in range(1,4):\n",
    "            if start-i >= 0:\n",
    "                dic[f'before_head2_prob{i}'] = preds2_all[start-i]\n",
    "                dic[f'before_other_prob{i}'] = preds4_all[start-i]\n",
    "                dic[f'before_other_type{i}'] = preds_type[start-i]\n",
    "                \n",
    "            if end+i < len(preds1_all):\n",
    "                dic[f'after_head2_prob{i}'] = preds2_all[end+i]\n",
    "                dic[f'after_other_prob{i}'] = preds4_all[end+i]\n",
    "                dic[f'after_other_type{i}'] = preds_type[end+i]\n",
    "\n",
    "\n",
    "        for mode in ['before', 'after']:\n",
    "            for iw, extend_L in enumerate([math.ceil(word_length/2), word_length]):\n",
    "                if mode == 'before':\n",
    "                    if start-extend_L<0:\n",
    "                        continue\n",
    "                    preds1_extend = preds1_all[start-extend_L:start]\n",
    "                    preds2_extend = preds2_all[start-extend_L:start]\n",
    "                else:\n",
    "                    if end+extend_L >=len(preds1_all):\n",
    "                        continue\n",
    "                    preds1_extend = preds1_all[end+1:end+extend_L]\n",
    "                    preds2_extend = preds2_all[end+1:end+extend_L]\n",
    "                    \n",
    "                if len(preds1_extend) == 0:\n",
    "                    continue\n",
    "                dic[f'{mode}{iw}_head_preds1'] = preds1_extend[0]\n",
    "                dic[f'{mode}{iw}_max_preds1'], dic[f'{mode}{iw}_min_preds1'], \\\n",
    "                dic[f'{mode}{iw}_sum_preds1'], dic[f'{mode}{iw}_mean_preds1'] = feat_speedup(preds1_extend)\n",
    "\n",
    "                dic[f'{mode}{iw}_head_preds2'] = preds2_extend[0]\n",
    "                dic[f'{mode}{iw}_max_preds2'], dic[f'{mode}{iw}_min_preds2'], \\\n",
    "                dic[f'{mode}{iw}_sum_preds2'], dic[f'{mode}{iw}_mean_preds2'] = feat_speedup(preds2_extend)\n",
    "\n",
    "                dic[f'{mode}{iw}_sum_preds1_rate'] = dic[f'{mode}{iw}_sum_preds1'] / dic[f'sum_preds1']\n",
    "                dic[f'{mode}{iw}_sum_preds2_rate'] = dic[f'{mode}{iw}_sum_preds2'] / dic[f'sum_preds2']\n",
    "                dic[f'{mode}{iw}_max_preds1_rate'] = dic[f'{mode}{iw}_max_preds1'] / dic[f'max_preds1']\n",
    "                dic[f'{mode}{iw}_max_preds2_rate'] = dic[f'{mode}{iw}_max_preds2'] / dic[f'max_preds2']\n",
    "\n",
    "        df_feat.append(dic)\n",
    "\n",
    "    return df_feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e39c83",
   "metadata": {
    "papermill": {
     "duration": 0.014919,
     "end_time": "2022-03-15T15:38:03.973784",
     "exception": false,
     "start_time": "2022-03-15T15:38:03.958865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### lgb predict and post choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98cc4a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:38:04.025629Z",
     "iopub.status.busy": "2022-03-15T15:38:04.020001Z",
     "iopub.status.idle": "2022-03-15T15:50:06.518956Z",
     "shell.execute_reply": "2022-03-15T15:50:06.520055Z",
     "shell.execute_reply.started": "2022-03-15T12:45:13.123664Z"
    },
    "papermill": {
     "duration": 722.530839,
     "end_time": "2022-03-15T15:50:06.520435",
     "exception": false,
     "start_time": "2022-03-15T15:38:03.989596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3119/3119 [12:00<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "proba_thresh = { \n",
    "    \"Lead\": 0.45,\n",
    "    \"Position\": 0.4,\n",
    "    \"Evidence\": 0.45,\n",
    "    \"Claim\": 0.35,\n",
    "    \"Concluding Statement\": 0.5,\n",
    "    \"Counterclaim\": 0.35,\n",
    "    \"Rebuttal\": 0.3,\n",
    "}\n",
    "\n",
    "inter_thresh = { \n",
    "    \"Lead\": 0.15,\n",
    "    \"Position\": 0.15,\n",
    "    \"Evidence\": 0.15,\n",
    "    \"Claim\": 0.25,\n",
    "    \"Concluding Statement\": 0.15,\n",
    "    \"Counterclaim\": 0.25,\n",
    "    \"Rebuttal\": 0.25,\n",
    "}\n",
    "\n",
    "\n",
    "def post_choice(df):\n",
    "    rtn = []\n",
    "    for k,group in df.groupby(['id','class']):\n",
    "        group = group.sort_values('lgb_prob',ascending=False)\n",
    "\n",
    "        preds_range = []\n",
    "        for irow, row in group.iterrows():\n",
    "            start = row.word_start\n",
    "            end = row.word_end\n",
    "            L1 = end-start+1\n",
    "            flag = 0\n",
    "            for pos_range in preds_range:\n",
    "                L2 = pos_range[1] - pos_range[0] + 1\n",
    "                intersection = (min(end, pos_range[1]) - max(start, pos_range[0]) + 1) / L1\n",
    "                inter_t = inter_thresh[row['class']]\n",
    "                if intersection>inter_t and (inter_t<=L1/L2<=1 or inter_t<=L2/L1<=1):\n",
    "                    flag = 1\n",
    "                    break\n",
    "\n",
    "            if flag == 0:\n",
    "                preds_range.append((start, end, row.lgb_prob))\n",
    "                rtn.append((row.id, row['class'], row.pos, row.word_start, row.word_end, row.lgb_prob))\n",
    "    rtn = pd.DataFrame(rtn, columns=['id','class','pos','start','end','lgb_prob'])\n",
    "    return rtn\n",
    "\n",
    "fold = 0\n",
    "lgb_model = pickle.load(open(f'../input/feedback-two-stage-data/lgb_fold{fold}.pkl','rb'))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "for id in tqdm(kfold_ids[fold][1]):\n",
    "    df_feat = pd.DataFrame(fun_get_feat(id))\n",
    "    \n",
    "    lgb_preds = lgb_model.predict(df_feat.drop(['id','pos'],axis=1))\n",
    "        \n",
    "    df_final = df_feat[['id', 'class','pos', 'word_start','word_end']].copy()\n",
    "    df_final['lgb_prob'] = lgb_preds\n",
    "    df_final['class'] = df_final['class'].map(lambda x:id2label[x])\n",
    "    \n",
    "    df_final['thre'] = df_final['class'].map(lambda x: proba_thresh[x])\n",
    "    df_final = df_final[df_final.lgb_prob>=df_final.thre]\n",
    "    df_final = post_choice(df_final)\n",
    "    \n",
    "    sub = pd.concat([sub, df_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976a4ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:50:08.557311Z",
     "iopub.status.busy": "2022-03-15T15:50:08.556473Z",
     "iopub.status.idle": "2022-03-15T15:50:08.837252Z",
     "shell.execute_reply": "2022-03-15T15:50:08.837820Z",
     "shell.execute_reply.started": "2022-03-15T12:56:02.106453Z"
    },
    "papermill": {
     "duration": 1.305057,
     "end_time": "2022-03-15T15:50:08.838022",
     "exception": false,
     "start_time": "2022-03-15T15:50:07.532965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictionstring(df):\n",
    "    predictionstring = []\n",
    "    for cache in df.values:\n",
    "        predictionstring.append(' '.join(list(map(str, range(cache[3], cache[4]+1)))))\n",
    "    return predictionstring\n",
    "\n",
    "\n",
    "sub['predictionstring'] = get_predictionstring(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe04932",
   "metadata": {
    "papermill": {
     "duration": 1.023708,
     "end_time": "2022-03-15T15:50:10.879533",
     "exception": false,
     "start_time": "2022-03-15T15:50:09.855825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### cv score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedc9ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:50:12.943107Z",
     "iopub.status.busy": "2022-03-15T15:50:12.942159Z",
     "iopub.status.idle": "2022-03-15T15:50:12.985153Z",
     "shell.execute_reply": "2022-03-15T15:50:12.984328Z",
     "shell.execute_reply.started": "2022-03-15T12:56:02.324124Z"
    },
    "papermill": {
     "duration": 1.084857,
     "end_time": "2022-03-15T15:50:12.985427",
     "exception": false,
     "start_time": "2022-03-15T15:50:11.900570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
    "    set_gt = set(row.predictionstring_gt.split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp_micro(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "\n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = (\n",
    "        gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]]\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    pred_df[\"pred_id\"] = pred_df.index\n",
    "    gt_df[\"gt_id\"] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(\n",
    "        gt_df,\n",
    "        left_on=[\"id\", \"class\"],\n",
    "        right_on=[\"id\", \"discourse_type\"],\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_pred\", \"_gt\"),\n",
    "    )\n",
    "    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
    "    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
    "    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
    "    tp_pred_ids = (\n",
    "        joined.query(\"potential_TP\")\n",
    "        .sort_values(\"max_overlap\", ascending=False)\n",
    "        .groupby([\"id\", \"predictionstring_gt\"])\n",
    "        .first()[\"pred_id\"]\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
    "    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    # calc microf1\n",
    "    f1_score = TP / (TP + 0.5 * (FP + FN))\n",
    "    precise_score = TP / (TP+FP)\n",
    "    recall_score = TP / (TP+FN)\n",
    "    \n",
    "    return {'f1':f1_score, 'precise':precise_score, 'recall':recall_score}\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df, return_class_scores=True):\n",
    "    class_scores = {}\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n",
    "        pred_subset = (\n",
    "            pred_df.loc[pred_df[\"class\"] == discourse_type]\n",
    "            .reset_index(drop=True)\n",
    "            .copy()\n",
    "        )\n",
    "        class_scores[discourse_type] = score_feedback_comp_micro(pred_subset, gt_subset)\n",
    "    f1 = np.mean([v['f1'] for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec8a71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T15:50:15.103864Z",
     "iopub.status.busy": "2022-03-15T15:50:15.101597Z",
     "iopub.status.idle": "2022-03-15T15:50:20.984257Z",
     "shell.execute_reply": "2022-03-15T15:50:20.983508Z",
     "shell.execute_reply.started": "2022-03-15T12:56:02.353593Z"
    },
    "papermill": {
     "duration": 6.91841,
     "end_time": "2022-03-15T15:50:20.984433",
     "exception": false,
     "start_time": "2022-03-15T15:50:14.066023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7486599909470771,\n",
       " {'Claim': {'f1': 0.6953852151454607,\n",
       "   'precise': 0.6819267896396827,\n",
       "   'recall': 0.7093855637303639},\n",
       "  'Concluding Statement': {'f1': 0.8941700705532863,\n",
       "   'precise': 0.8921822897369396,\n",
       "   'recall': 0.8961667286937105},\n",
       "  'Counterclaim': {'f1': 0.608619939050936,\n",
       "   'precise': 0.611013986013986,\n",
       "   'recall': 0.606244579358196},\n",
       "  'Evidence': {'f1': 0.7998428819931541,\n",
       "   'precise': 0.8188189338235294,\n",
       "   'recall': 0.7817264451025556},\n",
       "  'Lead': {'f1': 0.8867125463208047,\n",
       "   'precise': 0.8755880815473079,\n",
       "   'recall': 0.8981233243967829},\n",
       "  'Position': {'f1': 0.776555573797406,\n",
       "   'precise': 0.7867598137059215,\n",
       "   'recall': 0.766612641815235},\n",
       "  'Rebuttal': {'f1': 0.5793337097684924,\n",
       "   'precise': 0.5693673695893452,\n",
       "   'recall': 0.5896551724137931}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof = train_df[train_df.id.isin(kfold_ids[fold][1])]\n",
    "score_feedback_comp(sub, train_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f54dd",
   "metadata": {
    "papermill": {
     "duration": 1.063636,
     "end_time": "2022-03-15T15:50:23.086766",
     "exception": false,
     "start_time": "2022-03-15T15:50:22.023130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 778.015334,
   "end_time": "2022-03-15T15:50:26.859333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-15T15:37:28.843999",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
